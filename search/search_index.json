{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Virtlet is a Kubernetes runtime server which allows you to run VM workloads on your cluster. It can run arbitrary QCOW2 images, while making the VMs appear as pod-like as possible. This means the possibility of using most of standard kubectl commands, building higher-level Kubernetes objects such as StatefulSets or Deployments out of the VMs and so on. On the other hand, it's also suitable for running the traditional long-lived \"pet\" VMs, too. Virtlet has full support for Kubernetes networking and multiple CNI implementations, such as Calico, Weave and Flannel. In addition to this, more advanced CNI setups are supported, too, such as SR-IOV and using multiple CNI implementations at the same time. You can a Virtlet usage demo by following this link .","title":"Home"},{"location":"#introduction","text":"Virtlet is a Kubernetes runtime server which allows you to run VM workloads on your cluster. It can run arbitrary QCOW2 images, while making the VMs appear as pod-like as possible. This means the possibility of using most of standard kubectl commands, building higher-level Kubernetes objects such as StatefulSets or Deployments out of the VMs and so on. On the other hand, it's also suitable for running the traditional long-lived \"pet\" VMs, too. Virtlet has full support for Kubernetes networking and multiple CNI implementations, such as Calico, Weave and Flannel. In addition to this, more advanced CNI setups are supported, too, such as SR-IOV and using multiple CNI implementations at the same time. You can a Virtlet usage demo by following this link .","title":"Introduction"},{"location":"dev/architecture/","text":"General architecture diagram Virtlet networking architecture Other topics ... Block devices, the details of persistent rootfs/devicemapper, etc.","title":"Virtlet architecture"},{"location":"dev/architecture/#general-architecture-diagram","text":"","title":"General architecture diagram"},{"location":"dev/architecture/#virtlet-networking-architecture","text":"","title":"Virtlet networking architecture"},{"location":"dev/architecture/#other-topics","text":"Block devices, the details of persistent rootfs/devicemapper, etc.","title":"Other topics ..."},{"location":"dev/build-tool/","text":"build/cmd.sh","title":"Build Tool"},{"location":"dev/cirros/","text":"CirrOS build instructions","title":"Building a custom CirrOS image"},{"location":"dev/setup/","text":"Setting up the environment using kdc","title":"Setting up the environment"},{"location":"dev/tests/","text":"Unit tests Integration tests E2E tests","title":"Running the tests"},{"location":"dev/tests/#unit-tests","text":"","title":"Unit tests"},{"location":"dev/tests/#integration-tests","text":"","title":"Integration tests"},{"location":"dev/tests/#e2e-tests","text":"","title":"E2E tests"},{"location":"dev/virtlet-ci/","text":"The details of CircleCI setup Using CircleCI with your fork of Virtlet","title":"Virtlet CI"},{"location":"reference/cloud-init/","text":"Cloud-init options Virtlet uses Cloud-Init data generation mechanism for the following purposes: setting the host name based on the name of the pod injecting ssh keys setting up the VM network writing the contents of Secrets and ConfigMaps into the VM volume mounting setting up block devices based on PVs adding user-defined Cloud-Init settings such as startup scripts See also the list of annotations for the list of annotations that are used for Cloud-Init. Example Below is a pod definition that we'll be using. The annotations: part lists the cloud-init related annotations supported by Virtlet. apiVersion: v1 kind: Pod metadata: name: ubuntu-vm annotations: kubernetes.io/target-runtime: virtlet.cloud # override some fields in cloud-init meta-data VirtletCloudInitMetaData: | instance-id: foobar # override some fields in cloud-init user-data VirtletCloudInitUserData: | users: - name: cloudy gecos: Magic Cloud App Daemon User inactive: true system: true # this option disables merging of user-data keys. # By default the lists and dicts in user-data keys # are merged using the standard method (more on this below) # VirtletCloudInitUserDataOverwrite: true # this options makes it possible to write a script # in place of the user-data file. In case if this option # is present user-data part is not generated. # VirtletCloudInitUserDataScript: | # #!/bin/sh # echo hello world # it's also possible to use a configmap to override # parts of user-data VirtletCloudInitUserDataSource: configmap/vm-user-data # it's also possible to specify that the whole user-data contents # are stored in a ConfigMap under the specified key: # VirtletCloudInitUserDataSourceKey: user-data # by default, the contents of user-data in a ConfigMap key is specified # as plain text, but it can also be encoded using base64: # VirtletCloudInitUserDataSourceEncoding: base64 # Virtlet-specific annotations follow # Specify some ssh keys directly VirtletSSHKeys: | ssh-rsa AAAA... me@localhost ssh-rsa AAAA... me1@localhost # ssh keys may also be pulled from 'authorized_keys' key # in a ConfigMap or a Secret VirtletSSHKeySource: secret/mysecret # can also use the following: # VirtletSSHKeySource: configmap/configmap-with-public-keys spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: extraRuntime operator: In values: - virtlet containers: - name: ubuntu-vm image: virtlet.cloud/cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img volumeMounts: # this will write configmap contents using the `write_file` cloud-init module - name: config mountPath: /etc/foobar # this will write secret contents using the `write_file` cloud-init module - name: secret mountPath: /etc/baz # mount the qcow2 volume under /var/lib/docker - name: extra mountPath: /var/lib/docker # mount a raw device under /var/lib/postgresql - name: raw mountPath: /var/lib/postgresql # mount a ceph volume under /cephdata - name: ceph mountPath: /cephdata volumes: - name: config configMap: name: someconfig - name: secret secret: secretName: somesecret - name: extra flexVolume: driver: virtlet/flexvolume_driver options: type: qcow2 capacity: 2048MiB - name: raw flexVolume: driver: virtlet/flexvolume_driver options: type: raw path: /dev/mapper/somevg - name: ceph flexVolume: driver: virtlet/flexvolume_driver options: type: ceph monitor: 10.0.0.1:6789 user: libvirt secret: .... volume: rbd-test-image pool: libvirt-pool Cloud-init data generation The cloud-init data generated by Virtlet consists of meta-data , user-data and network-config parts. It's currently provided by means of NoCloud and Config Drive datasource, which in this case involves making an iso9660 image to be mounted by the VM. An implementation of either Amazon EC2 or OpenStack datasource can be added later. The cloud-init data is generated based on the following sources: pod name direct user-data/meta-data values from pod definition direct user-data/meta-data values from configmap/secret pod volumes and container mounts pod network configuration ssh keys specified either in pod definition or using a configmap/secret Output ISO image format Virtlet supports two types of Cloud-init ISO9660-based datasources, NoCloud and ConfigDrive. The user may choose an appropriate one using VirtletCloudInitImageType annotation, which can have either nocloud or configdrive as its value. When there's no VirtletCloudInitImageType annotation, Virtlet defaults to nocloud . Detailed structure of the generated files The meta-data part is a piece of JSON that looks like this: { instance-id : foobar , local-hostname : ubuntu-vm , public-keys : [ ssh-rsa AAAA... me@localhost , ssh-rsa AAAA... me1@localhost , ... ] } In case of ConfigDrive, this JSON has instance-id repeated as uuid and local-hostname repeated as hostname . We're using JSON format here so as to be compatible with older cloud-init implementations such as one used in CirrOS images which are used to test Virtlet. The following fields are generated by Virtlet: instance-id by default contains a name generated from pod name and pod namespace name separated with dot ( ubuntu-vm.default ). In this case it's overridden using VirtletCloudInitMetaData in the pod definition. Most of the time this field doesn't change much in the behavior of Virtlet VMs. local-hostname contains the name of the pod so VM's hostname defaults just to the pod name public-keys is a list of ssh public keys to put into the default user's ~/.ssh/authorized_keys file. It's taken either from VirtletSSHKeys annotation or from authorized_keys key in a kubernetes Secret on ConfigMap specified via VirtletSSHKeySource . The user-data part is only generated if it's not empty. It's a YAML file (because CirrOS doesn't support #cloud-config anyway) with the following content: #cloud-config mounts: - [ /dev/vdc1, /var/lib/docker ] - [ /dev/vdd, /var/lib/postgresql ] - [ /dev/vde, /cephdata ] write_files: - path: /etc/foobar/some-file-from-configmap.conf permissions: '0644' encoding: b64 content: IyB0aGlzIGlzIGEgc2FtcGxlIGNvbmZpZyBmaWxlCiMgdGFrZW4gZnJvbSBhIGNvbmZpZ21hcAo= - path: /etc/baz/a-file-taken-from-secrets.conf permissions: '0600' encoding: b64 content: IyBzb21lIHNlY3JldCBjb250ZW50Cg== - path: /foobar.txt content: this part is from a configmap specified using VirtletCloudInitUserDataSource users: - name: cloudy gecos: Magic Cloud App Daemon User inactive: true system: true Network configuration uses YAML to provide data in Network Config Version 1 . The user-data content is generated as follows: mounts are generated based on volumeMount options of the container and pod's volumes that are flexVolume s and use virtlet/flexvolume_driver . These are seen as block devices by the VM and Virtlet mounts them into appropriate directories write_files are generated based on configmaps and secrets mounted into the container. It also includes /etc/cloud/environment file (see Environment variable support for more info) and optionally /etc/cloud/mount-volumes.sh that can be used to mount volumes on systems without udev (see Workarounds for volume mounting below) the yaml content specified using optional VirtletCloudInitUserData annotation as well as the content from Secret or ConfigMap specified using another optional VirtletCloudInitUserDataSource annotation are merged together using a simple algorithm described in cloud-init documentation. During the merge, the autogenerated user-data comes first, then the contents of VirtletCloudInitUserData and finally the data taken from a Secret or ConfigMap specified via VirtletCloudInitUserDataSource it's possible to disable user-data merge algorithm and use the simple key replacement scheme by adding VirtletCloudInitUserDataOverwrite: true annotation it's also possible to replace the user-data file content entirely by adding VirtletCloudInitUserDataScript option. This may be useful if you want to pass a script there which may be necessary for older/simpler cloud-init implementations such as one used by CirrOS. Within the content of this script, @virtlet-mount-script@ can be replaced with volume mounting shell commands and commands for making symlinks for raw block volumes (see Workarounds for volume mounting below) Propagating user-data from Kubernetes objects In addition to putting user-data document right in the pod definition using VirtletCloudInitUserData annotation, it is possible to have this document stored in either ConfigMap or Secret kubernetes object. This is achieved with yet another annotation, called VirtletCloudInitUserDataSource . It has the following format: kind/name where kind is either configmap or secret and name is the name of appropriate resource. When virtlet sees this annotation, it reads the object it refers to and puts all its keys into the user-data dictionary. This is done at the very beginning of the user-data generation process. If the pod definition has both VirtletCloudInitUserData and VirtletCloudInitUserDataSource annotations, the virtlet will load user-data from kubernetes object and then will merge it with that from VirtletCloudInitUserData (unless VirtletCloudInitUserDataOverwrite is set to \"true\" , in which case VirtletCloudInitUserData will overwrite it). There's also an option to store the whole contents of user-data in a single key of ConfigMap which can be specified using VirtletCloudInitUserDataSourceKey . By default, the data are stored there as plain text but you can also specify base64 encoding via VirtletCloudInitUserDataSourceEncoding annotation. Similar approach is taken with SSH keys. It is possible to provide VM with a list of SSH keys obtained from ConfigMap or Secret kubernetes objects. In order to do so, one uses VirtletSSHKeySource annotation with the following format: kind/name/key . As for the user-data, kind is one of configmap , secret , name is the name of resource and key is the key name in that resource containing SSH keys in the same format in VirtletSSHKeys . The key part is optional. When using kind/name annotation (without key ), virtlet will look for the authorized_keys key. As with the user-data VirtletSSHKeys keys are going to be appended to those from VirtletSSHKeySource unless it is set to overwrite them by VirtletCloudInitUserDataOverwrite: \"true\" . Workarounds for volume mounting and raw block volumes Currenly Virtlet uses /dev/disk/by-path to mount volumes specified using Virtlet flexvolume driver. There's a problem with this approach however, namely that this depends on udev being used by the guest system. Moreover, some images (e.g. CirrOS example image) may have limited cloud-init support and may not provide proper user-data handling necessary to mount the block devices. To handle the first of this problem, Virtlet uses write_files section of user-data to write a shell script named /etc/cloud/mount-volumes.sh (the script uses /bin/sh ) that performs the necessary volume mounts using sysfs to look up the proper device names under /dev . The script also checks whether the volumes are already mounted so as not to mount them several times (so it's idempotent). Another slightly related problem is that when raw block volumes are used, symlinks must be created inside the VM that lead to the proper device files under /dev . This is done by means of /etc/cloud/symlink-devs.sh script that's injected via cloud-init. It's also automatically added to the runcmd section, so it gets executed on the first VM boot and linked from /var/lib/cloud/scripts/per-boot/ so that it gets executed on subsequent VM boots, too. In any case, this script gets executed after mounts are processed, so Virtlet updates mounts entries in the user-specified user-data that point to the raw block volume devices to make them work as if the symlinks were in place during the mounting. To deal with the systems without proper user-data support such as CirrOS, Virtlet makes it possible to specify @virtlet-mount-script@ inside VirtletCloudInitUserDataScript annotation. This string will be replaced with the content that's normally written to /etc/cloud/symlink-devs.sh and /etc/cloud/mount-volumes.sh (in this order). Given that the script starts with #!/bin/sh , you can use the following construct in the pod annotations: VirtletCloudInitUserDataScript: @virtlet-mount-script@ Additional links These links may help to understand some basics about cloud-init: Cloud-init documentation Booting cloud images with libvirt Install cloud-init on Ubuntu and use locally... NoCloud EC2 instance metadata Automating Openstack with cloud init run a script on VM's first boot Create a Linux Lab on KVM Using Cloud Images","title":"Cloud-Init"},{"location":"reference/cloud-init/#cloud-init-options","text":"Virtlet uses Cloud-Init data generation mechanism for the following purposes: setting the host name based on the name of the pod injecting ssh keys setting up the VM network writing the contents of Secrets and ConfigMaps into the VM volume mounting setting up block devices based on PVs adding user-defined Cloud-Init settings such as startup scripts See also the list of annotations for the list of annotations that are used for Cloud-Init.","title":"Cloud-init options"},{"location":"reference/cloud-init/#example","text":"Below is a pod definition that we'll be using. The annotations: part lists the cloud-init related annotations supported by Virtlet. apiVersion: v1 kind: Pod metadata: name: ubuntu-vm annotations: kubernetes.io/target-runtime: virtlet.cloud # override some fields in cloud-init meta-data VirtletCloudInitMetaData: | instance-id: foobar # override some fields in cloud-init user-data VirtletCloudInitUserData: | users: - name: cloudy gecos: Magic Cloud App Daemon User inactive: true system: true # this option disables merging of user-data keys. # By default the lists and dicts in user-data keys # are merged using the standard method (more on this below) # VirtletCloudInitUserDataOverwrite: true # this options makes it possible to write a script # in place of the user-data file. In case if this option # is present user-data part is not generated. # VirtletCloudInitUserDataScript: | # #!/bin/sh # echo hello world # it's also possible to use a configmap to override # parts of user-data VirtletCloudInitUserDataSource: configmap/vm-user-data # it's also possible to specify that the whole user-data contents # are stored in a ConfigMap under the specified key: # VirtletCloudInitUserDataSourceKey: user-data # by default, the contents of user-data in a ConfigMap key is specified # as plain text, but it can also be encoded using base64: # VirtletCloudInitUserDataSourceEncoding: base64 # Virtlet-specific annotations follow # Specify some ssh keys directly VirtletSSHKeys: | ssh-rsa AAAA... me@localhost ssh-rsa AAAA... me1@localhost # ssh keys may also be pulled from 'authorized_keys' key # in a ConfigMap or a Secret VirtletSSHKeySource: secret/mysecret # can also use the following: # VirtletSSHKeySource: configmap/configmap-with-public-keys spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: extraRuntime operator: In values: - virtlet containers: - name: ubuntu-vm image: virtlet.cloud/cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img volumeMounts: # this will write configmap contents using the `write_file` cloud-init module - name: config mountPath: /etc/foobar # this will write secret contents using the `write_file` cloud-init module - name: secret mountPath: /etc/baz # mount the qcow2 volume under /var/lib/docker - name: extra mountPath: /var/lib/docker # mount a raw device under /var/lib/postgresql - name: raw mountPath: /var/lib/postgresql # mount a ceph volume under /cephdata - name: ceph mountPath: /cephdata volumes: - name: config configMap: name: someconfig - name: secret secret: secretName: somesecret - name: extra flexVolume: driver: virtlet/flexvolume_driver options: type: qcow2 capacity: 2048MiB - name: raw flexVolume: driver: virtlet/flexvolume_driver options: type: raw path: /dev/mapper/somevg - name: ceph flexVolume: driver: virtlet/flexvolume_driver options: type: ceph monitor: 10.0.0.1:6789 user: libvirt secret: .... volume: rbd-test-image pool: libvirt-pool","title":"Example"},{"location":"reference/cloud-init/#cloud-init-data-generation","text":"The cloud-init data generated by Virtlet consists of meta-data , user-data and network-config parts. It's currently provided by means of NoCloud and Config Drive datasource, which in this case involves making an iso9660 image to be mounted by the VM. An implementation of either Amazon EC2 or OpenStack datasource can be added later. The cloud-init data is generated based on the following sources: pod name direct user-data/meta-data values from pod definition direct user-data/meta-data values from configmap/secret pod volumes and container mounts pod network configuration ssh keys specified either in pod definition or using a configmap/secret","title":"Cloud-init data generation"},{"location":"reference/cloud-init/#output-iso-image-format","text":"Virtlet supports two types of Cloud-init ISO9660-based datasources, NoCloud and ConfigDrive. The user may choose an appropriate one using VirtletCloudInitImageType annotation, which can have either nocloud or configdrive as its value. When there's no VirtletCloudInitImageType annotation, Virtlet defaults to nocloud .","title":"Output ISO image format"},{"location":"reference/cloud-init/#detailed-structure-of-the-generated-files","text":"The meta-data part is a piece of JSON that looks like this: { instance-id : foobar , local-hostname : ubuntu-vm , public-keys : [ ssh-rsa AAAA... me@localhost , ssh-rsa AAAA... me1@localhost , ... ] } In case of ConfigDrive, this JSON has instance-id repeated as uuid and local-hostname repeated as hostname . We're using JSON format here so as to be compatible with older cloud-init implementations such as one used in CirrOS images which are used to test Virtlet. The following fields are generated by Virtlet: instance-id by default contains a name generated from pod name and pod namespace name separated with dot ( ubuntu-vm.default ). In this case it's overridden using VirtletCloudInitMetaData in the pod definition. Most of the time this field doesn't change much in the behavior of Virtlet VMs. local-hostname contains the name of the pod so VM's hostname defaults just to the pod name public-keys is a list of ssh public keys to put into the default user's ~/.ssh/authorized_keys file. It's taken either from VirtletSSHKeys annotation or from authorized_keys key in a kubernetes Secret on ConfigMap specified via VirtletSSHKeySource . The user-data part is only generated if it's not empty. It's a YAML file (because CirrOS doesn't support #cloud-config anyway) with the following content: #cloud-config mounts: - [ /dev/vdc1, /var/lib/docker ] - [ /dev/vdd, /var/lib/postgresql ] - [ /dev/vde, /cephdata ] write_files: - path: /etc/foobar/some-file-from-configmap.conf permissions: '0644' encoding: b64 content: IyB0aGlzIGlzIGEgc2FtcGxlIGNvbmZpZyBmaWxlCiMgdGFrZW4gZnJvbSBhIGNvbmZpZ21hcAo= - path: /etc/baz/a-file-taken-from-secrets.conf permissions: '0600' encoding: b64 content: IyBzb21lIHNlY3JldCBjb250ZW50Cg== - path: /foobar.txt content: this part is from a configmap specified using VirtletCloudInitUserDataSource users: - name: cloudy gecos: Magic Cloud App Daemon User inactive: true system: true Network configuration uses YAML to provide data in Network Config Version 1 . The user-data content is generated as follows: mounts are generated based on volumeMount options of the container and pod's volumes that are flexVolume s and use virtlet/flexvolume_driver . These are seen as block devices by the VM and Virtlet mounts them into appropriate directories write_files are generated based on configmaps and secrets mounted into the container. It also includes /etc/cloud/environment file (see Environment variable support for more info) and optionally /etc/cloud/mount-volumes.sh that can be used to mount volumes on systems without udev (see Workarounds for volume mounting below) the yaml content specified using optional VirtletCloudInitUserData annotation as well as the content from Secret or ConfigMap specified using another optional VirtletCloudInitUserDataSource annotation are merged together using a simple algorithm described in cloud-init documentation. During the merge, the autogenerated user-data comes first, then the contents of VirtletCloudInitUserData and finally the data taken from a Secret or ConfigMap specified via VirtletCloudInitUserDataSource it's possible to disable user-data merge algorithm and use the simple key replacement scheme by adding VirtletCloudInitUserDataOverwrite: true annotation it's also possible to replace the user-data file content entirely by adding VirtletCloudInitUserDataScript option. This may be useful if you want to pass a script there which may be necessary for older/simpler cloud-init implementations such as one used by CirrOS. Within the content of this script, @virtlet-mount-script@ can be replaced with volume mounting shell commands and commands for making symlinks for raw block volumes (see Workarounds for volume mounting below)","title":"Detailed structure of the generated files"},{"location":"reference/cloud-init/#propagating-user-data-from-kubernetes-objects","text":"In addition to putting user-data document right in the pod definition using VirtletCloudInitUserData annotation, it is possible to have this document stored in either ConfigMap or Secret kubernetes object. This is achieved with yet another annotation, called VirtletCloudInitUserDataSource . It has the following format: kind/name where kind is either configmap or secret and name is the name of appropriate resource. When virtlet sees this annotation, it reads the object it refers to and puts all its keys into the user-data dictionary. This is done at the very beginning of the user-data generation process. If the pod definition has both VirtletCloudInitUserData and VirtletCloudInitUserDataSource annotations, the virtlet will load user-data from kubernetes object and then will merge it with that from VirtletCloudInitUserData (unless VirtletCloudInitUserDataOverwrite is set to \"true\" , in which case VirtletCloudInitUserData will overwrite it). There's also an option to store the whole contents of user-data in a single key of ConfigMap which can be specified using VirtletCloudInitUserDataSourceKey . By default, the data are stored there as plain text but you can also specify base64 encoding via VirtletCloudInitUserDataSourceEncoding annotation. Similar approach is taken with SSH keys. It is possible to provide VM with a list of SSH keys obtained from ConfigMap or Secret kubernetes objects. In order to do so, one uses VirtletSSHKeySource annotation with the following format: kind/name/key . As for the user-data, kind is one of configmap , secret , name is the name of resource and key is the key name in that resource containing SSH keys in the same format in VirtletSSHKeys . The key part is optional. When using kind/name annotation (without key ), virtlet will look for the authorized_keys key. As with the user-data VirtletSSHKeys keys are going to be appended to those from VirtletSSHKeySource unless it is set to overwrite them by VirtletCloudInitUserDataOverwrite: \"true\" .","title":"Propagating user-data from Kubernetes objects"},{"location":"reference/cloud-init/#workarounds-for-volume-mounting-and-raw-block-volumes","text":"Currenly Virtlet uses /dev/disk/by-path to mount volumes specified using Virtlet flexvolume driver. There's a problem with this approach however, namely that this depends on udev being used by the guest system. Moreover, some images (e.g. CirrOS example image) may have limited cloud-init support and may not provide proper user-data handling necessary to mount the block devices. To handle the first of this problem, Virtlet uses write_files section of user-data to write a shell script named /etc/cloud/mount-volumes.sh (the script uses /bin/sh ) that performs the necessary volume mounts using sysfs to look up the proper device names under /dev . The script also checks whether the volumes are already mounted so as not to mount them several times (so it's idempotent). Another slightly related problem is that when raw block volumes are used, symlinks must be created inside the VM that lead to the proper device files under /dev . This is done by means of /etc/cloud/symlink-devs.sh script that's injected via cloud-init. It's also automatically added to the runcmd section, so it gets executed on the first VM boot and linked from /var/lib/cloud/scripts/per-boot/ so that it gets executed on subsequent VM boots, too. In any case, this script gets executed after mounts are processed, so Virtlet updates mounts entries in the user-specified user-data that point to the raw block volume devices to make them work as if the symlinks were in place during the mounting. To deal with the systems without proper user-data support such as CirrOS, Virtlet makes it possible to specify @virtlet-mount-script@ inside VirtletCloudInitUserDataScript annotation. This string will be replaced with the content that's normally written to /etc/cloud/symlink-devs.sh and /etc/cloud/mount-volumes.sh (in this order). Given that the script starts with #!/bin/sh , you can use the following construct in the pod annotations: VirtletCloudInitUserDataScript: @virtlet-mount-script@","title":"Workarounds for volume mounting and raw block volumes"},{"location":"reference/cloud-init/#additional-links","text":"These links may help to understand some basics about cloud-init: Cloud-init documentation Booting cloud images with libvirt Install cloud-init on Ubuntu and use locally... NoCloud EC2 instance metadata Automating Openstack with cloud init run a script on VM's first boot Create a Linux Lab on KVM Using Cloud Images","title":"Additional links"},{"location":"reference/config/","text":"Using per-node configuration In order to use per-node configuration, you need to create Virtlet CRD definitions before you deploy Virtlet: virtletctl gen --crd | kubectl apply -f - After that, you can add one or more Virtlet configuration mappings: kubectl apply -f - EOF --- apiVersion: virtlet.k8s/v1 kind: VirtletConfigMapping metadata: name: test namespace: kube-system spec: nodeName: kube-node-2 priority: 1 config: disableKVM: true logLevel: 5 rawDevices: sda*,loop* --- apiVersion: virtlet.k8s/v1 kind: VirtletConfigMapping metadata: name: test-labels namespace: kube-system spec: nodeSelector: foo: bar priority: 10 config: logLevel: 3 EOF You can delete Virtlet pods to have them restarted and pick up the changes after you add, remove or modify the configuration mappings. All the config mappings must reside in kube-system namespace. Each mapping can specify nodeSelector or nodeName to target a subset of the nodes. If neither nodeSelector nor nodeName is specified, the mapping will target all the nodes. If the several mappings apply to the node, their order is determined by priority value, with mappings with higher value of priority taking precendence. config specifies the list of configuration fields (see the full table of config fields in the next section of this document). In the example above, for the node named kube-node-2 , KVM is disabled, log level is set to 5 and the raw device list is set to sda*,loop* . For nodes with foo=bar label, the log level is overridden and set to 3. If kube-node-2 node has foo=bar label, the log level will be set to 3 there as the label-based mapping has higher priority. Configuration options summary The table below lists all the Virtlet configuration fields, with their corresponding command line flags and environment variables that are handled by Virtlet binary. Note that you may only need these environment variables and configuration flags if you're not using the standard Virtlet deployment YAML as generated by virtletctl gen . Description Config field Default value Type Command line flag / Env Path to fd server socket fdServerSocketPath /var/lib/virtlet/tapfdserver.sock string --fd-server-socket-path / VIRTLET_FD_SERVER_SOCKET_PATH Path to the virtlet database databasePath /var/lib/virtlet/virtlet.db string --database-path / VIRTLET_DATABASE_PATH Image download protocol. Can be https or http downloadProtocol https string --image-download-protocol / VIRTLET_DOWNLOAD_PROTOCOL Image directory imageDir /var/lib/virtlet/images string --image-dir / VIRTLET_IMAGE_DIR Image name translation configs directory imageTranslationConfigsDir /etc/virtlet/images string --image-translation-configs-dir / VIRTLET_IMAGE_TRANSLATIONS_DIR Libvirt connection URI libvirtURI qemu:///system string --libvirt-uri / VIRTLET_LIBVIRT_URI Comma separated list of raw device glob patterns which VMs can access (without '/dev/' prefix) rawDevices loop* string --raw-devices / VIRTLET_RAW_DEVICES The path to UNIX domain socket for CRI service to listen on criSocketPath /run/virtlet.sock string --listen / VIRTLET_CRI_SOCKET_PATH Display logging and the streamer disableLogging false boolean --disable-logging / VIRTLET_DISABLE_LOGGING Forcibly disable KVM support disableKVM false boolean --disable-kvm / VIRTLET_DISABLE_KVM Enable SR-IOV support enableSriov false boolean --enable-sriov / VIRTLET_SRIOV_SUPPORT Path to CNI plugin binaries cniPluginDir /opt/cni/bin string --cni-bin-dir / VIRTLET_CNI_PLUGIN_DIR Path to the CNI configuration directory cniConfigDir /etc/cni/net.d string --cni-conf-dir / VIRTLET_CNI_CONFIG_DIR Calico subnet size to use calicoSubnetSize 24 integer --calico-subnet-size / VIRTLET_CALICO_SUBNET Enable regexp image name translation enableRegexpImageTranslation true boolean --enable-regexp-image-translation / IMAGE_REGEXP_TRANSLATION CPU model to use in libvirt domain definition (libvirt's default value will be used if not set) cpuModel string --cpu-model / VIRTLET_CPU_MODEL configurable port to the virtlet server streamPort 10010 integer --stream-port / VIRTLET_STREAM_PORT Log level to use logLevel 1 integer --v / VIRTLET_LOGLEVEL Only the following config fields mentioned in this table can be used with standard Virtlet deployment YAML: downloadProtocol , rawDevices , disableKVM , enableSriov , calicoSubnetSize , enableRegexpImageTranslation , cpuModel and logLevel . Other options may need adjusting the YAML to change the paths of volume mounts. disableLogging option is intended for debugging purposes only.","title":"Configuration"},{"location":"reference/config/#using-per-node-configuration","text":"In order to use per-node configuration, you need to create Virtlet CRD definitions before you deploy Virtlet: virtletctl gen --crd | kubectl apply -f - After that, you can add one or more Virtlet configuration mappings: kubectl apply -f - EOF --- apiVersion: virtlet.k8s/v1 kind: VirtletConfigMapping metadata: name: test namespace: kube-system spec: nodeName: kube-node-2 priority: 1 config: disableKVM: true logLevel: 5 rawDevices: sda*,loop* --- apiVersion: virtlet.k8s/v1 kind: VirtletConfigMapping metadata: name: test-labels namespace: kube-system spec: nodeSelector: foo: bar priority: 10 config: logLevel: 3 EOF You can delete Virtlet pods to have them restarted and pick up the changes after you add, remove or modify the configuration mappings. All the config mappings must reside in kube-system namespace. Each mapping can specify nodeSelector or nodeName to target a subset of the nodes. If neither nodeSelector nor nodeName is specified, the mapping will target all the nodes. If the several mappings apply to the node, their order is determined by priority value, with mappings with higher value of priority taking precendence. config specifies the list of configuration fields (see the full table of config fields in the next section of this document). In the example above, for the node named kube-node-2 , KVM is disabled, log level is set to 5 and the raw device list is set to sda*,loop* . For nodes with foo=bar label, the log level is overridden and set to 3. If kube-node-2 node has foo=bar label, the log level will be set to 3 there as the label-based mapping has higher priority.","title":"Using per-node configuration"},{"location":"reference/config/#configuration-options-summary","text":"The table below lists all the Virtlet configuration fields, with their corresponding command line flags and environment variables that are handled by Virtlet binary. Note that you may only need these environment variables and configuration flags if you're not using the standard Virtlet deployment YAML as generated by virtletctl gen . Description Config field Default value Type Command line flag / Env Path to fd server socket fdServerSocketPath /var/lib/virtlet/tapfdserver.sock string --fd-server-socket-path / VIRTLET_FD_SERVER_SOCKET_PATH Path to the virtlet database databasePath /var/lib/virtlet/virtlet.db string --database-path / VIRTLET_DATABASE_PATH Image download protocol. Can be https or http downloadProtocol https string --image-download-protocol / VIRTLET_DOWNLOAD_PROTOCOL Image directory imageDir /var/lib/virtlet/images string --image-dir / VIRTLET_IMAGE_DIR Image name translation configs directory imageTranslationConfigsDir /etc/virtlet/images string --image-translation-configs-dir / VIRTLET_IMAGE_TRANSLATIONS_DIR Libvirt connection URI libvirtURI qemu:///system string --libvirt-uri / VIRTLET_LIBVIRT_URI Comma separated list of raw device glob patterns which VMs can access (without '/dev/' prefix) rawDevices loop* string --raw-devices / VIRTLET_RAW_DEVICES The path to UNIX domain socket for CRI service to listen on criSocketPath /run/virtlet.sock string --listen / VIRTLET_CRI_SOCKET_PATH Display logging and the streamer disableLogging false boolean --disable-logging / VIRTLET_DISABLE_LOGGING Forcibly disable KVM support disableKVM false boolean --disable-kvm / VIRTLET_DISABLE_KVM Enable SR-IOV support enableSriov false boolean --enable-sriov / VIRTLET_SRIOV_SUPPORT Path to CNI plugin binaries cniPluginDir /opt/cni/bin string --cni-bin-dir / VIRTLET_CNI_PLUGIN_DIR Path to the CNI configuration directory cniConfigDir /etc/cni/net.d string --cni-conf-dir / VIRTLET_CNI_CONFIG_DIR Calico subnet size to use calicoSubnetSize 24 integer --calico-subnet-size / VIRTLET_CALICO_SUBNET Enable regexp image name translation enableRegexpImageTranslation true boolean --enable-regexp-image-translation / IMAGE_REGEXP_TRANSLATION CPU model to use in libvirt domain definition (libvirt's default value will be used if not set) cpuModel string --cpu-model / VIRTLET_CPU_MODEL configurable port to the virtlet server streamPort 10010 integer --stream-port / VIRTLET_STREAM_PORT Log level to use logLevel 1 integer --v / VIRTLET_LOGLEVEL Only the following config fields mentioned in this table can be used with standard Virtlet deployment YAML: downloadProtocol , rawDevices , disableKVM , enableSriov , calicoSubnetSize , enableRegexpImageTranslation , cpuModel and logLevel . Other options may need adjusting the YAML to change the paths of volume mounts. disableLogging option is intended for debugging purposes only.","title":"Configuration options summary"},{"location":"reference/diagnostics/","text":"Direct invocation The most basic diagnostics command is virtletctl diag dump : $ virtletctl diag out/ $ ls -lR out total 0 drwxr-xr-x 3 user wheel 96 Jul 11 01:56 nodes out/nodes: total 0 drwxr-xr-x 12 user wheel 384 Jul 11 01:56 kube-node-1 out/nodes/kube-node-1: total 5352 -rwxr-xr-x 1 user wheel 1276000 Jul 11 01:56 criproxy.log -rwxr-xr-x 1 user wheel 1787 Jul 11 01:56 ip-a.txt -rwxr-xr-x 1 user wheel 322 Jul 11 01:56 ip-r.txt drwxr-xr-x 3 user wheel 96 Jul 11 01:56 libvirt-logs drwxr-xr-x 5 user wheel 160 Jul 11 01:56 libvirt-xml -rwxr-xr-x 1 user wheel 9964 Jul 11 01:56 metadata.txt -rwxr-xr-x 1 user wheel 1443 Jul 11 01:56 netns.txt -rwxr-xr-x 1 user wheel 9217 Jul 11 02:56 psaux.txt -rwxr-xr-x 1 user wheel 18214 Jul 11 01:56 stack.log -rwxr-xr-x 1 user wheel 64314 Jul 11 01:56 virtlet-pod-libvirt.log -rwxr-xr-x 1 user wheel 1349763 Jul 11 01:56 virtlet-pod-virtlet.log out/nodes/kube-node-1/libvirt-logs: total 8 -rwxr-xr-x 1 user wheel 2172 Jul 11 01:56 virtlet-1b2261ca-7ed6-cirros-vm.log out/nodes/kube-node-1/libvirt-xml: total 24 -rwxr-xr-x 1 user wheel 3511 Jul 11 01:56 domain-virtlet-1b2261ca-7ed6-cirros-vm.xml -rwxr-xr-x 1 user wheel 445 Jul 11 01:56 pool-volumes.xml -rwxr-xr-x 1 user wheel 1041 Jul 11 01:56 volume-virtlet_root_1b2261ca-7ed6-58e7-58de-0eef2c9d5320.xml The following files and directories are produced for each Kubernetes node that runs Virtlet: criproxy.log - the logs of CRI Proxy's systemd unit ip-a.txt - the output of ip a on the node ip-r.txt - the output of ip r on the node metadata.txt - the contents of Virtlet's internal metadata db in a text form netns.txt - the output of ip a and ip r for each network namespace that's managed by Virtlet psaux.txt - the output of ps aux command on the node stack.log - the dump of Go stack of Virtlet process virtlet-pod-libvirt.log - the log of Virtlet pod's libvirt container virtlet-pod-virtlet.log - the log of Virtlet pod's virtlet container livirt-logs - a directory with libvirt/QEMU logs for each domain libvirt-xml - the dumps of all the domains, storage pools and storage volumes in libvirt It's also possible to dump Virtlet diagnostics as JSON to stdout using virtletctl diag dump --json . The JSON file can be subsequently unpacked into the aforementioned directory structure using virtletctl diag unpack . Sonobuoy Virtlet diagnostics can be run as a Sonobuoy plugin. Unfortunately, right now Sonobuoy's plugin support is somewhat limited . Because of that problem, Sonobuoy run must be done in two phases, first generating YAML and then using virtletctl to patch it (inject Virtlet sonobuoy plugin): $ cat sonobuoy.json { plugins : [ { name : virtlet } ] } $ sonobuoy gen --config sonobuoy.json --e2e-focus nosuchtest | virtletctl diag sonobuoy | kubectl apply -f - $ # wait till sonobuoy run is complete $ sonobuoy status PLUGIN STATUS COUNT virtlet complete 1 Sonobuoy has completed. Use `sonobuoy retrieve` to get results. $ sonobuoy retrieve The diagnostics results are placed under plugins/virtlet/results and can be unpacked using virtletctl diag unpack : $ virtletctl diag unpack out/ sonobuoy_output_dir/plugins/virtlet/results","title":"Diagnostics"},{"location":"reference/diagnostics/#direct-invocation","text":"The most basic diagnostics command is virtletctl diag dump : $ virtletctl diag out/ $ ls -lR out total 0 drwxr-xr-x 3 user wheel 96 Jul 11 01:56 nodes out/nodes: total 0 drwxr-xr-x 12 user wheel 384 Jul 11 01:56 kube-node-1 out/nodes/kube-node-1: total 5352 -rwxr-xr-x 1 user wheel 1276000 Jul 11 01:56 criproxy.log -rwxr-xr-x 1 user wheel 1787 Jul 11 01:56 ip-a.txt -rwxr-xr-x 1 user wheel 322 Jul 11 01:56 ip-r.txt drwxr-xr-x 3 user wheel 96 Jul 11 01:56 libvirt-logs drwxr-xr-x 5 user wheel 160 Jul 11 01:56 libvirt-xml -rwxr-xr-x 1 user wheel 9964 Jul 11 01:56 metadata.txt -rwxr-xr-x 1 user wheel 1443 Jul 11 01:56 netns.txt -rwxr-xr-x 1 user wheel 9217 Jul 11 02:56 psaux.txt -rwxr-xr-x 1 user wheel 18214 Jul 11 01:56 stack.log -rwxr-xr-x 1 user wheel 64314 Jul 11 01:56 virtlet-pod-libvirt.log -rwxr-xr-x 1 user wheel 1349763 Jul 11 01:56 virtlet-pod-virtlet.log out/nodes/kube-node-1/libvirt-logs: total 8 -rwxr-xr-x 1 user wheel 2172 Jul 11 01:56 virtlet-1b2261ca-7ed6-cirros-vm.log out/nodes/kube-node-1/libvirt-xml: total 24 -rwxr-xr-x 1 user wheel 3511 Jul 11 01:56 domain-virtlet-1b2261ca-7ed6-cirros-vm.xml -rwxr-xr-x 1 user wheel 445 Jul 11 01:56 pool-volumes.xml -rwxr-xr-x 1 user wheel 1041 Jul 11 01:56 volume-virtlet_root_1b2261ca-7ed6-58e7-58de-0eef2c9d5320.xml The following files and directories are produced for each Kubernetes node that runs Virtlet: criproxy.log - the logs of CRI Proxy's systemd unit ip-a.txt - the output of ip a on the node ip-r.txt - the output of ip r on the node metadata.txt - the contents of Virtlet's internal metadata db in a text form netns.txt - the output of ip a and ip r for each network namespace that's managed by Virtlet psaux.txt - the output of ps aux command on the node stack.log - the dump of Go stack of Virtlet process virtlet-pod-libvirt.log - the log of Virtlet pod's libvirt container virtlet-pod-virtlet.log - the log of Virtlet pod's virtlet container livirt-logs - a directory with libvirt/QEMU logs for each domain libvirt-xml - the dumps of all the domains, storage pools and storage volumes in libvirt It's also possible to dump Virtlet diagnostics as JSON to stdout using virtletctl diag dump --json . The JSON file can be subsequently unpacked into the aforementioned directory structure using virtletctl diag unpack .","title":"Direct invocation"},{"location":"reference/diagnostics/#sonobuoy","text":"Virtlet diagnostics can be run as a Sonobuoy plugin. Unfortunately, right now Sonobuoy's plugin support is somewhat limited . Because of that problem, Sonobuoy run must be done in two phases, first generating YAML and then using virtletctl to patch it (inject Virtlet sonobuoy plugin): $ cat sonobuoy.json { plugins : [ { name : virtlet } ] } $ sonobuoy gen --config sonobuoy.json --e2e-focus nosuchtest | virtletctl diag sonobuoy | kubectl apply -f - $ # wait till sonobuoy run is complete $ sonobuoy status PLUGIN STATUS COUNT virtlet complete 1 Sonobuoy has completed. Use `sonobuoy retrieve` to get results. $ sonobuoy retrieve The diagnostics results are placed under plugins/virtlet/results and can be unpacked using virtletctl diag unpack : $ virtletctl diag unpack out/ sonobuoy_output_dir/plugins/virtlet/results","title":"Sonobuoy"},{"location":"reference/images/","text":"VM Image Handling Virtlet supports QCOW2 format for VM images. The image is specified in the image field of the container definition and must have virtlet.cloud/ prefix. If no image name translation is specified, the URL for the QCOW2 file is constructed by prepending https:// (the default) or http:// to the rest of the image name of virtlet.cloud/ prefix, with any image tags stripped. The protocol to use is controlled via downloadProtocol config option . ImagePullSecrets are not supported at the moment, but you can use image name translation to use client TLS certificates or specify user:password@ as a part of the URL. An example of container definition: containers: - name: test-vm image: download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img Restrictions and pitfalls Image names are subject to the strict validation rules that normally applied to the docker image names. Thus one cannot just put arbitrary URL into the image name. In particular, image names cannot have capital letters, colons and some other characters that are commonly found in the URLs. Using image name with invalid characters is a common reason for VM creation failure with non-obvious error status. In order to overcome these limitations, Virtlet provides image name translation that allows to use alias name for the image and define how this alias translates into the URL along with additional transport options elsewhere. Image Name Translation By default, the image URL is encoded into image name as described above . However, due to the strict rules for the image name format such approach has number of significant restrictions: Colon cannot appear in the name. Thus the URL cannot include scheme part ( http:// or https:// ). As a consequence it becomes impossible use images that have scheme that differs from configured default. For the same reasons it's impossible to use URLs that include queries, authentication credentials or a port number. The URL must be all lower-case which works well for the domain part, but may not be acceptable for the path part. To overcome these limitations, Virtlet provides a mechanism for image name translation. The idea is that image can be identified by some abstract ID rather than URL. Virtlet then will map this ID to arbitrary URL using special translation table that specifies rules for image name translation. Thus instead of virtlet.cloud/example.net/path/to/my.qcow2 one would use virtlet.cloud/my-image and put a mapping that says that my-image must be translated to http://example.net/path/to/my.qcow2 into translation table. Here and below we assume that CRI Proxy is used. Otherwise, the virtlet.cloud/ prefix is not needed. Translation configs The translation table is built from arbitrary number of translation configs. The config has the following format: prefix: my-prefix translations: - name: cirros url: https://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img - name: ubuntu/16.04 url: https://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img - regexp: 'cirros/(\\d\\.\\d\\.\\d)' url: 'https://download.cirros-cloud.net/$1/cirros-$1-x86_64-disk.img' - regexp: 'centos/(\\d+)-(\\d+)' url: 'https://cloud.centos.org/centos/$1/images/CentOS-$1-x86_64-GenericCloud-$2.qcow2' The prefix is optional and may be omitted. In example above the image name virtlet.cloud/my-prefix/cirros is going to be translated into https://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img , but virtlet.cloud/cirros won't be unless there is also a translation config without a prefix (or with empty string prefix). In the later case, the cirros part will be treated as an URL (the default behavior without translations). There are two types of translations: those that map a fixed image name and those that map set of names identified by regexp expression. In the later case, URL can be generalized by using regexp sub-matches through the $n syntax. In example above, virtlet.cloud/my-prefix/centos/7-01 is going to be translated to https://cloud.centos.org/centos/$1/images/CentOS-7-x86_64-GenericCloud-01.qcow2 . The regexp translations are only available when Virtlet is run with IMAGE_REGEXP_TRANSLATION environment variable set to a non-empty value, which is not the case by default. Fixed name translations has a higher precedence than regexp ones. Thus for ambiguous names, fixed name translations are always preferred. Creating translation configs There are two ways how translation configs can be delivered to Virtlet: Through static YAML files Through custom Kubernetes resource VirtletImageMapping In the first case the translation configs are read from the yaml files from a directory in the virtlet container. There are many ways, how files can be put into virtlet container. Default Virtlet setup uses ConfigMap-based volume to mount deploy/images.yaml into /etc/virtlet/images path inside the Virtlet container. The path is provide to Virtlet through the imageTranslationConfigsDir config option . The flag is optional, and, when omitted, completely disables file-based translation configs. With the second method, the configs are provided through custom Kubernetes resource VirtletImageMapping which looks as following: apiVersion: virtlet.k8s/v1 kind: VirtletImageMapping metadata: name: primary namespace: kube-system spec: prefix: translations: - ... - ... where a translation config is placed into spec field and wrapped with usual Kubernetes metadata. One can use kubectl apply -f mappings.yaml to create such resources. But for this to be possible VirtletImageMapping resource kind must be registered in Kubernetes. Virtlet does it on the first run. This such mappings cannot be created in the Kubernetes cluster that never had Virtlet running. There can be any number of VirtletImageMapping resource. However, currently all such mappings must be in the kube-system namespace. VirtletImageMapping resource have a precedence over file-based configs for ambiguous image names. Thus it is convenient to put defaults into static config files and then override them with VirtletImageMapping resources when needed. Configure HTTP transport for image download By default, the image downloader uses default transport settings: system-wide CA certificates for HTTPS URLs, up to 9 redirects and proxy from the HTTP_PROXY / HTTPS_PROXY environment variables. However, with image translation configs it is possible to override these default and provide custom transport configuration. Transport settings are grouped into profiles, each with the name and bunch of configuration settings. Each translation rule may optionally have transport attribute set to profile name to be used for the image URL of that rule. Below is an example of translation config that has all possible transport settings though all of them are optional: translations: - name: mySmallImage url: https://my.host.loc/small.qcow2 transport: my-server - name: myImage url: https://my.host.loc/big.qcow2 transport: my-server transports: my-server: timeout: 30000 # in ms. 0 = no timeout (default) maxRedirects: 1 # at most 1 redirect allowed (i.e. 2 HTTP requests). null or missing value = any number of redirects proxy: http://my-proxy.loc:8080 tls: # optional TLS settings. Use default system settings when not specified certificates: # there can be any mumber of certificates. Both CA and client certificates are put here - cert: | -----BEGIN CERTIFICATE----- # CA PEM block goes here # CA certificates are recognized by IsCA:TRUE flag in the certificate. Private key is not needed in this case # CA certificates are appended to the Linux system-wide list -----END CERTIFICATE----- - cert: | -----BEGIN CERTIFICATE----- # Client-based authentication certificate PEM block goes here # There can be several certificates put together if they share a single key -----END CERTIFICATE----- key: | -----BEGIN RSA PRIVATE KEY----- # PEM-encoded private key # for certificate-based client authentication private key must be present # Also the key is not required if it already contained in the cert PEM -----END RSA PRIVATE KEY----- serverName: my.host.com # because the certificate is for .com but we're connecting to .loc insecure: false # when true, no server certificate validation is going to be performed When no transport profile is specified for translation rule, the default system settings are used. However, since the default value for transport attribute is an empty string, defining profile with empty name can be used to override this default for all images in that particular config: translations: - name: mySmallImage url: https://my.host.loc/small.qcow2 - name: myImage url: https://my.host.loc/big.qcow2 transports: : proxy: http://my-proxy.loc:8080 # proxy for all images without explicit transport name Of course, the same settings can be put into VirtletImageMapping objects: apiVersion: virtlet.k8s/v1 kind: VirtletImageMapping metadata: name: primary namespace: kube-system spec: translations: - name: mySmallImage url: https://my.host.loc/small.qcow2 - name: myImage url: https://my.host.loc/big.qcow2 transports: : proxy: http://my-proxy.loc:8080 # proxy for all images without explicit transport name The details of Virtlet image storage Virtlet uses filesystem-based image store for the VM images. The images are stored like this: /var/lib/virtlet/images links/ example.com%whatever%etc - ../data/2d711642b726b04401627ca9fbac32f5c8530fb1903cc4db02258717921a4881 example.com%same%image - ../data/2d711642b726b04401627ca9fbac32f5c8530fb1903cc4db02258717921a4881 anotherimg - ../data/a1fce4363854ff888cff4b8e7875d600c2682390412a8cf79b37d0b11148b0fa data/ 2d711642b726b04401627ca9fbac32f5c8530fb1903cc4db02258717921a4881 a1fce4363854ff888cff4b8e7875d600c2682390412a8cf79b37d0b11148b0fa The files are downloaded to data/ . File names correspond to SHA256 hashes of their content. The images are pulled upon PullImage gRPC request made by kubelet. Files are named part_SOME_RANDOM_STRING while being downloaded. After the download finishes, SHA256 hash is calculated to be used as the data file name, and if the file with that name already exists, the newly downloaded file is removed, otherwise it's renamed to that SHA256 digest string. In both cases a symbolic link is created with the name equal to docker image name but with / replaced by % , with the link target being the matching data file. The image store performs GC upon Virtlet startup, which consists of removing any part_* files and those files in data/ which have no symlinks leading to them aren't being used by any containers. The VMs are started from QCOW2 volumes which use the boot images as backing store files. The images are stored under /var/lib/libvirt/images/data . VM volumes are stored in \" volumes \" libvirt pool under /var/lib/virtlet/volumes during the VM execution time and are automatically garbage collected by Virtlet after stopping VM pod environment (sandbox). Note: Virtlet currently ignores image tags, but their meaning may change in future, so it\u2019s better not to set them for VM pods. If there\u2019s no tag provided in the image specification kubelet defaults to imagePullPolicy: Always , which means that the image is always redownloaded when the pod is created. In order to make pod creation faster and more reliable, we set in examples imagePullPolicy to IfNotPresent so a previously downloaded image is reused if there is one in Virtlet\u2019s image store.","title":"VM Image Handling"},{"location":"reference/images/#vm-image-handling","text":"Virtlet supports QCOW2 format for VM images. The image is specified in the image field of the container definition and must have virtlet.cloud/ prefix. If no image name translation is specified, the URL for the QCOW2 file is constructed by prepending https:// (the default) or http:// to the rest of the image name of virtlet.cloud/ prefix, with any image tags stripped. The protocol to use is controlled via downloadProtocol config option . ImagePullSecrets are not supported at the moment, but you can use image name translation to use client TLS certificates or specify user:password@ as a part of the URL. An example of container definition: containers: - name: test-vm image: download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img","title":"VM Image Handling"},{"location":"reference/images/#restrictions-and-pitfalls","text":"Image names are subject to the strict validation rules that normally applied to the docker image names. Thus one cannot just put arbitrary URL into the image name. In particular, image names cannot have capital letters, colons and some other characters that are commonly found in the URLs. Using image name with invalid characters is a common reason for VM creation failure with non-obvious error status. In order to overcome these limitations, Virtlet provides image name translation that allows to use alias name for the image and define how this alias translates into the URL along with additional transport options elsewhere.","title":"Restrictions and pitfalls"},{"location":"reference/images/#image-name-translation","text":"By default, the image URL is encoded into image name as described above . However, due to the strict rules for the image name format such approach has number of significant restrictions: Colon cannot appear in the name. Thus the URL cannot include scheme part ( http:// or https:// ). As a consequence it becomes impossible use images that have scheme that differs from configured default. For the same reasons it's impossible to use URLs that include queries, authentication credentials or a port number. The URL must be all lower-case which works well for the domain part, but may not be acceptable for the path part. To overcome these limitations, Virtlet provides a mechanism for image name translation. The idea is that image can be identified by some abstract ID rather than URL. Virtlet then will map this ID to arbitrary URL using special translation table that specifies rules for image name translation. Thus instead of virtlet.cloud/example.net/path/to/my.qcow2 one would use virtlet.cloud/my-image and put a mapping that says that my-image must be translated to http://example.net/path/to/my.qcow2 into translation table. Here and below we assume that CRI Proxy is used. Otherwise, the virtlet.cloud/ prefix is not needed.","title":"Image Name Translation"},{"location":"reference/images/#translation-configs","text":"The translation table is built from arbitrary number of translation configs. The config has the following format: prefix: my-prefix translations: - name: cirros url: https://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img - name: ubuntu/16.04 url: https://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img - regexp: 'cirros/(\\d\\.\\d\\.\\d)' url: 'https://download.cirros-cloud.net/$1/cirros-$1-x86_64-disk.img' - regexp: 'centos/(\\d+)-(\\d+)' url: 'https://cloud.centos.org/centos/$1/images/CentOS-$1-x86_64-GenericCloud-$2.qcow2' The prefix is optional and may be omitted. In example above the image name virtlet.cloud/my-prefix/cirros is going to be translated into https://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img , but virtlet.cloud/cirros won't be unless there is also a translation config without a prefix (or with empty string prefix). In the later case, the cirros part will be treated as an URL (the default behavior without translations). There are two types of translations: those that map a fixed image name and those that map set of names identified by regexp expression. In the later case, URL can be generalized by using regexp sub-matches through the $n syntax. In example above, virtlet.cloud/my-prefix/centos/7-01 is going to be translated to https://cloud.centos.org/centos/$1/images/CentOS-7-x86_64-GenericCloud-01.qcow2 . The regexp translations are only available when Virtlet is run with IMAGE_REGEXP_TRANSLATION environment variable set to a non-empty value, which is not the case by default. Fixed name translations has a higher precedence than regexp ones. Thus for ambiguous names, fixed name translations are always preferred.","title":"Translation configs"},{"location":"reference/images/#creating-translation-configs","text":"There are two ways how translation configs can be delivered to Virtlet: Through static YAML files Through custom Kubernetes resource VirtletImageMapping In the first case the translation configs are read from the yaml files from a directory in the virtlet container. There are many ways, how files can be put into virtlet container. Default Virtlet setup uses ConfigMap-based volume to mount deploy/images.yaml into /etc/virtlet/images path inside the Virtlet container. The path is provide to Virtlet through the imageTranslationConfigsDir config option . The flag is optional, and, when omitted, completely disables file-based translation configs. With the second method, the configs are provided through custom Kubernetes resource VirtletImageMapping which looks as following: apiVersion: virtlet.k8s/v1 kind: VirtletImageMapping metadata: name: primary namespace: kube-system spec: prefix: translations: - ... - ... where a translation config is placed into spec field and wrapped with usual Kubernetes metadata. One can use kubectl apply -f mappings.yaml to create such resources. But for this to be possible VirtletImageMapping resource kind must be registered in Kubernetes. Virtlet does it on the first run. This such mappings cannot be created in the Kubernetes cluster that never had Virtlet running. There can be any number of VirtletImageMapping resource. However, currently all such mappings must be in the kube-system namespace. VirtletImageMapping resource have a precedence over file-based configs for ambiguous image names. Thus it is convenient to put defaults into static config files and then override them with VirtletImageMapping resources when needed.","title":"Creating translation configs"},{"location":"reference/images/#configure-http-transport-for-image-download","text":"By default, the image downloader uses default transport settings: system-wide CA certificates for HTTPS URLs, up to 9 redirects and proxy from the HTTP_PROXY / HTTPS_PROXY environment variables. However, with image translation configs it is possible to override these default and provide custom transport configuration. Transport settings are grouped into profiles, each with the name and bunch of configuration settings. Each translation rule may optionally have transport attribute set to profile name to be used for the image URL of that rule. Below is an example of translation config that has all possible transport settings though all of them are optional: translations: - name: mySmallImage url: https://my.host.loc/small.qcow2 transport: my-server - name: myImage url: https://my.host.loc/big.qcow2 transport: my-server transports: my-server: timeout: 30000 # in ms. 0 = no timeout (default) maxRedirects: 1 # at most 1 redirect allowed (i.e. 2 HTTP requests). null or missing value = any number of redirects proxy: http://my-proxy.loc:8080 tls: # optional TLS settings. Use default system settings when not specified certificates: # there can be any mumber of certificates. Both CA and client certificates are put here - cert: | -----BEGIN CERTIFICATE----- # CA PEM block goes here # CA certificates are recognized by IsCA:TRUE flag in the certificate. Private key is not needed in this case # CA certificates are appended to the Linux system-wide list -----END CERTIFICATE----- - cert: | -----BEGIN CERTIFICATE----- # Client-based authentication certificate PEM block goes here # There can be several certificates put together if they share a single key -----END CERTIFICATE----- key: | -----BEGIN RSA PRIVATE KEY----- # PEM-encoded private key # for certificate-based client authentication private key must be present # Also the key is not required if it already contained in the cert PEM -----END RSA PRIVATE KEY----- serverName: my.host.com # because the certificate is for .com but we're connecting to .loc insecure: false # when true, no server certificate validation is going to be performed When no transport profile is specified for translation rule, the default system settings are used. However, since the default value for transport attribute is an empty string, defining profile with empty name can be used to override this default for all images in that particular config: translations: - name: mySmallImage url: https://my.host.loc/small.qcow2 - name: myImage url: https://my.host.loc/big.qcow2 transports: : proxy: http://my-proxy.loc:8080 # proxy for all images without explicit transport name Of course, the same settings can be put into VirtletImageMapping objects: apiVersion: virtlet.k8s/v1 kind: VirtletImageMapping metadata: name: primary namespace: kube-system spec: translations: - name: mySmallImage url: https://my.host.loc/small.qcow2 - name: myImage url: https://my.host.loc/big.qcow2 transports: : proxy: http://my-proxy.loc:8080 # proxy for all images without explicit transport name","title":"Configure HTTP transport for image download"},{"location":"reference/images/#the-details-of-virtlet-image-storage","text":"Virtlet uses filesystem-based image store for the VM images. The images are stored like this: /var/lib/virtlet/images links/ example.com%whatever%etc - ../data/2d711642b726b04401627ca9fbac32f5c8530fb1903cc4db02258717921a4881 example.com%same%image - ../data/2d711642b726b04401627ca9fbac32f5c8530fb1903cc4db02258717921a4881 anotherimg - ../data/a1fce4363854ff888cff4b8e7875d600c2682390412a8cf79b37d0b11148b0fa data/ 2d711642b726b04401627ca9fbac32f5c8530fb1903cc4db02258717921a4881 a1fce4363854ff888cff4b8e7875d600c2682390412a8cf79b37d0b11148b0fa The files are downloaded to data/ . File names correspond to SHA256 hashes of their content. The images are pulled upon PullImage gRPC request made by kubelet. Files are named part_SOME_RANDOM_STRING while being downloaded. After the download finishes, SHA256 hash is calculated to be used as the data file name, and if the file with that name already exists, the newly downloaded file is removed, otherwise it's renamed to that SHA256 digest string. In both cases a symbolic link is created with the name equal to docker image name but with / replaced by % , with the link target being the matching data file. The image store performs GC upon Virtlet startup, which consists of removing any part_* files and those files in data/ which have no symlinks leading to them aren't being used by any containers. The VMs are started from QCOW2 volumes which use the boot images as backing store files. The images are stored under /var/lib/libvirt/images/data . VM volumes are stored in \" volumes \" libvirt pool under /var/lib/virtlet/volumes during the VM execution time and are automatically garbage collected by Virtlet after stopping VM pod environment (sandbox). Note: Virtlet currently ignores image tags, but their meaning may change in future, so it\u2019s better not to set them for VM pods. If there\u2019s no tag provided in the image specification kubelet defaults to imagePullPolicy: Always , which means that the image is always redownloaded when the pod is created. In order to make pod creation faster and more reliable, we set in examples imagePullPolicy to IfNotPresent so a previously downloaded image is reused if there is one in Virtlet\u2019s image store.","title":"The details of Virtlet image storage"},{"location":"reference/injecting-files/","text":"Injecting files into the VM Virtlet makes it possible to write set of files to the root filesystem of a VM using Config Map or Secret as a source of data. Key-value conventions ConfigMap or Secret should contain keys and values according to the following convention: entry: content entry_path: encoded/path/in/filesystem entry_encoding: encoding_of_content second_entry: content second_entry_path: encoded/path/in/filesystem second_entry_encoding: encoding_of_content where entry is an arbitrary name, entry_name contains the destination path on the VM root filesystem, and optional entry_encoding denotes the encoding of the file content which can be plain for plain text (for use in ConfigMaps) or base64 (the default). ConfigMap example Create a ConfigMap like this: kubectl apply -f - EOF apiVersion: v1 kind: ConfigMap metadata: name: my-files-set data: locale: LANG= pl_PL.UTF-8 locale_path: /etc/locale.conf locale_encoding: plain host_conf: bXVsdGkgb2ZmCg== host_conf_path: /etc/host.conf EOF and then add it to a pod using the following annotation: ... metadata: ... annotations: VirtletFilesFromDataSource: configmap/my-files-set Secret example Same data as show above can be specified via a Secret : mkdir data echo 'LANG= pl_PL.UTF-8 ' data/locale echo /etc/locale.conf data/locale_path echo multi off data/host_conf echo /etc/host.conf data/host_conf_path kubectl create secret generic my-files-set --from-file=data/ rm -r data/ or recreating above using yaml notation (note: secrets use base64 encoding for each value stored under each key): kubectl apply -f - EOF apiVersion: v1 kind: Secret metadata: name: my-files-set data: locale: TEFORz0icGxfUEwuVVRGLTgiCg== locale_path: L2V0Yy9sb2NhbGUuY29uZgo= host_conf: bXVsdGkgb2ZmCg== host_conf_path: L2V0Yy9ob3N0LmNvbmYK EOF The secret can be injected into the root filesystem like that: ... metadata: ... annotations: VirtletFilesFromDataSource: secret/my-files-set","title":"Injecting Files into the VM"},{"location":"reference/injecting-files/#injecting-files-into-the-vm","text":"Virtlet makes it possible to write set of files to the root filesystem of a VM using Config Map or Secret as a source of data.","title":"Injecting files into the VM"},{"location":"reference/injecting-files/#key-value-conventions","text":"ConfigMap or Secret should contain keys and values according to the following convention: entry: content entry_path: encoded/path/in/filesystem entry_encoding: encoding_of_content second_entry: content second_entry_path: encoded/path/in/filesystem second_entry_encoding: encoding_of_content where entry is an arbitrary name, entry_name contains the destination path on the VM root filesystem, and optional entry_encoding denotes the encoding of the file content which can be plain for plain text (for use in ConfigMaps) or base64 (the default).","title":"Key-value conventions"},{"location":"reference/injecting-files/#configmap-example","text":"Create a ConfigMap like this: kubectl apply -f - EOF apiVersion: v1 kind: ConfigMap metadata: name: my-files-set data: locale: LANG= pl_PL.UTF-8 locale_path: /etc/locale.conf locale_encoding: plain host_conf: bXVsdGkgb2ZmCg== host_conf_path: /etc/host.conf EOF and then add it to a pod using the following annotation: ... metadata: ... annotations: VirtletFilesFromDataSource: configmap/my-files-set","title":"ConfigMap example"},{"location":"reference/injecting-files/#secret-example","text":"Same data as show above can be specified via a Secret : mkdir data echo 'LANG= pl_PL.UTF-8 ' data/locale echo /etc/locale.conf data/locale_path echo multi off data/host_conf echo /etc/host.conf data/host_conf_path kubectl create secret generic my-files-set --from-file=data/ rm -r data/ or recreating above using yaml notation (note: secrets use base64 encoding for each value stored under each key): kubectl apply -f - EOF apiVersion: v1 kind: Secret metadata: name: my-files-set data: locale: TEFORz0icGxfUEwuVVRGLTgiCg== locale_path: L2V0Yy9sb2NhbGUuY29uZgo= host_conf: bXVsdGkgb2ZmCg== host_conf_path: L2V0Yy9ob3N0LmNvbmYK EOF The secret can be injected into the root filesystem like that: ... metadata: ... annotations: VirtletFilesFromDataSource: secret/my-files-set","title":"Secret example"},{"location":"reference/networking/","text":"Virtlet networking principles Supported CNI implementations Configuring using DHCP Configuring using Cloud-Init Not supported for persistent rootfs for now Setting up Multiple CNIs SR-IOV","title":"Networking"},{"location":"reference/networking/#virtlet-networking-principles","text":"","title":"Virtlet networking principles"},{"location":"reference/networking/#supported-cni-implementations","text":"","title":"Supported CNI implementations"},{"location":"reference/networking/#configuring-using-dhcp","text":"","title":"Configuring using DHCP"},{"location":"reference/networking/#configuring-using-cloud-init","text":"Not supported for persistent rootfs for now","title":"Configuring using Cloud-Init"},{"location":"reference/networking/#setting-up-multiple-cnis","text":"","title":"Setting up Multiple CNIs"},{"location":"reference/networking/#sr-iov","text":"","title":"SR-IOV"},{"location":"reference/resources/","text":"CPU Model By default, libvirt runs QEMU with a CPU model that doesn't support nested virtualization. It's possible to change this behavior by using VirtletCPUModel: host-model annotation in the pod definition. You can also use cpuModel value in Virtlet config to override the value globally for the cluster or for a particular subset of nodes. If you are familiar with the cpu part in libvirt domain definition, you can use VirtletLibvirtCPUSetting annotation, the value is directly passed to libvirt after reading it from yaml string. It is more flexible than usage of VirtletCPUModel as it allows to provide more detailed configuration. For example: annotations: VirtletLibvirtCPUSetting: | mode: custom model: value: Westmere features: - name: avx policy: disable See cpuSetting for a full example. Resource monitoring on the node As Kubelet uses cAdvisor to collect metrics about running containers and Virtlet doesn't create container per each VM, and instead spawns VMs inside Virtlet container. This leads to all the resource usage being lumped together and ascribed to Virtlet pod. CPU management CPU cgroups facilities: shares - relative value of cpu time assigned, not recommended for using in production as it's hard to predict the actual performance which highly depends on the neighboring cgroups. CFS CPU bandwidth control - period and quota - hard limits. Parent_Period/Quota = Child_1_Period/Quota + .. + Child_N_Period/Quota , where Child_N_Period/Quota = Parent_Period/Quota . K8s CPU allocation: shares are set per container. CFS CPU bandwidth control - period and quota - are set per container. Defaults: In absence of explicitly set values each container has 2 shares set by default. Libvirt CPU allocation: shares is set per each vCPU. period and quota are set per each vCPU. As libvirt imposes limits per each vCPU thread, so actual CPU quota is quota value from the domain definition times the number of vCPUs. More details re reasons of libvirt per vCPU cgroup approach can be found there . emulator_period and emulator_quota denote the limits for emulator threads (those excluding vcpus). At the same time for unlimited domains benchmarks show that these activities may measure up to 40-80% of overall physical CPU usage by QEMU/KVM process running the guest VM. vCPUs per VM - it's commonly recommended to have vCPU count set to 1 (see details in section \"CPU overcommit\" below). Defaults: In absence of explicitly set values each domain has 1024 shares set by default. CPU overcommit It's outlined that linux scheduler doesn't perform well in case of CPU overcommitment and if it's not caused real need (like having multi-core VM to perform build/compile, running application inside that can effectively utilize multiple cores and was designed for parallel processing) and widely recommended to use one vCPU per VM otherwise you can expect performance degradation. It is not recommended to have more than 10 virtual CPUs per physical processor core. Any number of overcommitted virtual CPUs above the number of physical processor cores may cause problems with certain virtualized guests, so it's always up to cluster administrators how to set up number vCPUs per VMs. See more considerations on KVM limitations . Virtlet CPU resources management By default, all VMs are created with 1 vCPU. To change vCPU number for VM-Pod you have to add annotation VirtletVCPUCount with desired number, see examples/cirros-vm.yaml . Due to p.2 in \"Libvirt CPU Allocation\" Virtlet spreads the assigned CPU resource limit equally among VM's vCPU threads. According to p.3 in \"Libvirt CPU Allocation\" Virtlet must set limits for emulator threads(those excluding vcpus). At this time Virtlet doesn't support setting these values, but there are plans to fix this in future. Memory management K8s memory allocation Setting memory limit to 0 or omitting it means there's no memory limit for the container. K8s doesn't support swap on the nodes (for example, k8s creates docker containers with --memory-swappiness=0, see more at https://github.com/kubernetes/kubernetes/issues/7294). Libvirt memory allocation memory - allocated RAM memory at VM boot. memtune= hard_limit - cgroup memory limit on all domain including qemu itself usage. However, it's claimed that such limit should be set accurately . Swap unlimited by default. Memory overcommit Overcommit memory value can reach ~150% of physical RAM amount. This relies on assumption that most processes do not access 100% of their allocated memory all the time. So you can grant guest VMs more RAM than actually is available on the host. However, this strongly depends on memory swap size available on the node and workloads of VMs memory consumptions. For more details check Overcommitting with KVM . Virtlet Memory resources management By default, each VM is assigned 1GB of RAM. To set other value you need set resource memory limit for container, see examples/cirros-vm.yaml . Virtlet generates domain XML with memoryBacking=locked setting to prevent swapping out domain's pages. Summary of the action items: According to 2 and 3 in \"Libvirt CPU Allocation\" we need to invent some rule of setting CFS CPU bandwidth limit spread among QEMU and vCPU threads, so as to make k8s scheduler have right assumptions about the resources allocated on the node. Research how to configure the hard limits on memory for VM pod.","title":"Resource management"},{"location":"reference/resources/#cpu-model","text":"By default, libvirt runs QEMU with a CPU model that doesn't support nested virtualization. It's possible to change this behavior by using VirtletCPUModel: host-model annotation in the pod definition. You can also use cpuModel value in Virtlet config to override the value globally for the cluster or for a particular subset of nodes. If you are familiar with the cpu part in libvirt domain definition, you can use VirtletLibvirtCPUSetting annotation, the value is directly passed to libvirt after reading it from yaml string. It is more flexible than usage of VirtletCPUModel as it allows to provide more detailed configuration. For example: annotations: VirtletLibvirtCPUSetting: | mode: custom model: value: Westmere features: - name: avx policy: disable See cpuSetting for a full example.","title":"CPU Model"},{"location":"reference/resources/#resource-monitoring-on-the-node","text":"As Kubelet uses cAdvisor to collect metrics about running containers and Virtlet doesn't create container per each VM, and instead spawns VMs inside Virtlet container. This leads to all the resource usage being lumped together and ascribed to Virtlet pod.","title":"Resource monitoring on the node"},{"location":"reference/resources/#cpu-management","text":"","title":"CPU management"},{"location":"reference/resources/#cpu-cgroups-facilities","text":"shares - relative value of cpu time assigned, not recommended for using in production as it's hard to predict the actual performance which highly depends on the neighboring cgroups. CFS CPU bandwidth control - period and quota - hard limits. Parent_Period/Quota = Child_1_Period/Quota + .. + Child_N_Period/Quota , where Child_N_Period/Quota = Parent_Period/Quota .","title":"CPU cgroups facilities:"},{"location":"reference/resources/#k8s-cpu-allocation","text":"shares are set per container. CFS CPU bandwidth control - period and quota - are set per container. Defaults: In absence of explicitly set values each container has 2 shares set by default.","title":"K8s CPU allocation:"},{"location":"reference/resources/#libvirt-cpu-allocation","text":"shares is set per each vCPU. period and quota are set per each vCPU. As libvirt imposes limits per each vCPU thread, so actual CPU quota is quota value from the domain definition times the number of vCPUs. More details re reasons of libvirt per vCPU cgroup approach can be found there . emulator_period and emulator_quota denote the limits for emulator threads (those excluding vcpus). At the same time for unlimited domains benchmarks show that these activities may measure up to 40-80% of overall physical CPU usage by QEMU/KVM process running the guest VM. vCPUs per VM - it's commonly recommended to have vCPU count set to 1 (see details in section \"CPU overcommit\" below). Defaults: In absence of explicitly set values each domain has 1024 shares set by default.","title":"Libvirt CPU allocation:"},{"location":"reference/resources/#cpu-overcommit","text":"It's outlined that linux scheduler doesn't perform well in case of CPU overcommitment and if it's not caused real need (like having multi-core VM to perform build/compile, running application inside that can effectively utilize multiple cores and was designed for parallel processing) and widely recommended to use one vCPU per VM otherwise you can expect performance degradation. It is not recommended to have more than 10 virtual CPUs per physical processor core. Any number of overcommitted virtual CPUs above the number of physical processor cores may cause problems with certain virtualized guests, so it's always up to cluster administrators how to set up number vCPUs per VMs. See more considerations on KVM limitations .","title":"CPU overcommit"},{"location":"reference/resources/#virtlet-cpu-resources-management","text":"By default, all VMs are created with 1 vCPU. To change vCPU number for VM-Pod you have to add annotation VirtletVCPUCount with desired number, see examples/cirros-vm.yaml . Due to p.2 in \"Libvirt CPU Allocation\" Virtlet spreads the assigned CPU resource limit equally among VM's vCPU threads. According to p.3 in \"Libvirt CPU Allocation\" Virtlet must set limits for emulator threads(those excluding vcpus). At this time Virtlet doesn't support setting these values, but there are plans to fix this in future.","title":"Virtlet CPU resources management"},{"location":"reference/resources/#memory-management","text":"","title":"Memory management"},{"location":"reference/resources/#k8s-memory-allocation","text":"Setting memory limit to 0 or omitting it means there's no memory limit for the container. K8s doesn't support swap on the nodes (for example, k8s creates docker containers with --memory-swappiness=0, see more at https://github.com/kubernetes/kubernetes/issues/7294).","title":"K8s memory allocation"},{"location":"reference/resources/#libvirt-memory-allocation","text":"memory - allocated RAM memory at VM boot. memtune= hard_limit - cgroup memory limit on all domain including qemu itself usage. However, it's claimed that such limit should be set accurately . Swap unlimited by default.","title":"Libvirt memory allocation"},{"location":"reference/resources/#memory-overcommit","text":"Overcommit memory value can reach ~150% of physical RAM amount. This relies on assumption that most processes do not access 100% of their allocated memory all the time. So you can grant guest VMs more RAM than actually is available on the host. However, this strongly depends on memory swap size available on the node and workloads of VMs memory consumptions. For more details check Overcommitting with KVM .","title":"Memory overcommit"},{"location":"reference/resources/#virtlet-memory-resources-management","text":"By default, each VM is assigned 1GB of RAM. To set other value you need set resource memory limit for container, see examples/cirros-vm.yaml . Virtlet generates domain XML with memoryBacking=locked setting to prevent swapping out domain's pages.","title":"Virtlet Memory resources management"},{"location":"reference/resources/#summary-of-the-action-items","text":"According to 2 and 3 in \"Libvirt CPU Allocation\" we need to invent some rule of setting CFS CPU bandwidth limit spread among QEMU and vCPU threads, so as to make k8s scheduler have right assumptions about the resources allocated on the node. Research how to configure the hard limits on memory for VM pod.","title":"Summary of the action items:"},{"location":"reference/vm-pod-spec/","text":"Defining a VM Pod The basic idea of a VM pod is that it's a plain Kubernetes pod definition with the following conditions satisfied: It has kubernetes.io/target-runtime: virtlet.cloud annotation so it can be recognized by CRI Proxy . The pod has exactly one container. The container's image has virtlet.cloud/ prefix followed by the image name which is recognized according to Virtlet's image handling rules and used to download the QCOW2 image for the VM. If you have Virtlet running only on some of the nodes in the cluster, you also need to specify either nodeSelector or nodeAffinity for the pod to have it land on a node with Virtlet. If a VM pod lands on a node which doesn't have Virtlet or where Virtlet and CRI Proxy aren't configured properly, you can see the following messages in kubectl describe output for the VM pod (the message can be printed as a single line): Warning Failed 5s (x2 over 17s) kubelet, kubemaster Failed to pull image virtlet.cloud/cirros : rpc error: code = Unknown desc = Error response from daemon: Get https://virtlet.cloud/v2/: dial tcp 50.63.202.10:443: connect: connection refused This means that kubelet is trying to pull the VM image from a Docker registry. It's also possible to construct higher-level Kubernetes objects such as Deployment, StatefulSet or DaemonSet out of VM pods, in which case the template section of the object must follow the above rules for VM pods. Below is an example of a Virtlet pod. The comments describe the particular parts of the pod spec. The following sections will give more details on each part of the spec. # Standard k8s pod header apiVersion: v1 kind: Pod metadata: # the name of the pod name: cirros-vm # See 'Annotations recognized by Virtlet' below annotations: # This tells CRI Proxy that this pod belongs to Virtlet runtime kubernetes.io/target-runtime: virtlet.cloud # An optional annotation specifying the count of virtual CPUs. # Defaults to 1 . VirtletVCPUCount: 1 # CirrOS doesn't load nocloud data from SCSI CD-ROM for some reason VirtletDiskDriver: virtio # inject ssh keys via cloud-init VirtletSSHKeys: | ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCaJEcFDXEK2ZbX0ZLS1EIYFZRbDAcRfuVjpstSc0De8+sV1aiu+dePxdkuDRwqFtCyk6dEZkssjOkBXtri00MECLkir6FcH3kKOJtbJ6vy3uaJc9w1ERo+wyl6SkAh/+JTJkp7QRXj8oylW5E20LsbnA/dIwWzAF51PPwF7A7FtNg9DnwPqMkxFo1Th/buOMKbP5ZA1mmNNtmzbMpMfJATvVyiv3ccsSJKOiyQr6UG+j7sc/7jMVz5Xk34Vd0l8GwcB0334MchHckmqDB142h/NCWTr8oLakDNvkfC1YneAfAO41hDkUbxPtVBG5M/o7P4fxoqiHEX+ZLfRxDtHB53 me@localhost # set root volume size VirtletRootVolumeSize: 1Gi spec: # This nodeAffinity specification tells Kubernetes to run this # pod only on the nodes that have extraRuntime=virtlet label. # This label is used by Virtlet DaemonSet to select nodes # that must have Virtlet runtime affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: extraRuntime operator: In values: - virtlet containers: - name: cirros-vm # This specifies the image to use. # virtlet.cloud/ prefix is used by CRI proxy, the remaining part # of the image name is prepended with https:// and used to download the image image: virtlet.cloud/cirros imagePullPolicy: IfNotPresent # tty and stdin required for `kubectl attach -t` to work tty: true stdin: true resources: limits: # This memory limit is applied to the libvirt domain definition memory: 160Mi Annotations recognized by Virtlet The annotations can be specified under annotations key of the metadata part of the pod spec. Note that the values are always strings, but they can be parsed in different way by Virtlet (see Type column). For boolean keys, the string \"true\" (lowercase) is interpreted as a true value. All other values are interpreted as false. Several keys belong to the Cloud-Init settings which are described in detail in the corresponding section . Key Description Value Default kubernetes.io/target-runtime CRI runtime setting for CRI Proxy virtlet.cloud virtlet.cloud VirtletChown9pfsMounts Recursively chown 9pfs mounts boolean \"\" VirtletCloudInitImageType Cloud-Init image type to use \"nocloud\" \"configdrive\" \"\" VirtletCloudInitMetaData The contents of Cloud-Init metadata json / yaml \"\" VirtletCloudInitUserData The contents of Cloud-Init user-data (mergeable) json / yaml \"\" VirtletCloudInitUserDataOverwrite Disable merging of Cloud-Init user-data keys boolean \"\" VirtletCloudInitUserDataScript The contents of Cloud-Init user-data as a script text \"\" VirtletCloudInitUserDataSource Data source for Cloud-Init user-data \"configmap/...\" \"secret/...\" \"\" VirtletCloudInitUserDataSourceEncoding Encoding to use for loading Cloud-Init user-data from a ConfigMap key \"plain\" \"base|4\" VirtletCloudInitUserDataSourceKey ConfigMap key to load Cloud-Init user-data from \"\" VirtletCPUModel CPU model to use \"\" \"host-model\" \"\" VirtletDiskDriver Disk driver to use \"scsi\" \"virtio\" \"scsi\" VirtletFilesFromDataSource Inject files from a ConfigMap or a Secret into the image \"configmap/...\" \"secret/...\" \"\" VirtletLibvirtCPUSetting libvirt CPU model setting yaml \"\" VirtletRootVolumeSize Root volume size quantity \"\" VirtletSSHKeys SSH keys to add to the VM injected via Cloud-Init a list of strings \"\" VirtletSSHKeySource Data source for ssh keys injected via Cloud-Init \"configmap/...\" \"secret/...\" \"\" VirtletVCPUCount The number of vCPUs to assign to the VM pod integer \"1\" CRI Proxy annotation Besides Virtlet annotations, there's kubernetes.io/target-runtime: virtlet.cloud annotation which is handled by CRI Proxy . It's important to specify it as well as virtlet.cloud prefix for CRI Proxy to be able to direct requests to Virtlet. Chowning 9pfs mounts Setting VirtletChown9pfsMounts to true causes 9pfs mounts to chown their volume contents to make it readable and writable by the VM. CPU Model VirtletCPUModel: host-model annotation enables nested virtualization. VirtletLibvirtCPUSetting is an expert-only annotation that sets the CPU options for libvirt. The YAML keys correspond to the XML elements and attributes in the libvirt XML definition , but are capitalized. The value of Model field goes into the Value key. For example: Match: exact Model: Fallback: allow Value: core2duo Disk driver The driver is set using VirtletDiskDriver annotation which may have the value of scsi (the default) or virtio . Some OS images may have problem with the default scsi driver, for example, CirrOS can't handle Cloud-Init data unless virtio driver is used. Injecting files into the image By using VirtletFilesFromDataSource annotation, it's possible to place the contents of a ConfigMap or a Secret on the image before booting the VM. For more information, refer to Injecting files into the VM . vCPU count Virtlet defaults to using just one vCPU per VM. You can change this value by setting VirtletVCPUCount annotation to the desired value, for example, VirtletVCPUCount: \"2\" . Volume handling Virtlet can recognize and handle pod's volumes and container's volumeMounts sections. This can also be used to make the VM use a persistent root filesystem which will survive pod removal and re-creation. For more information on working with volumes, please refer to the Volumes section. Environment variables Virtlet supports passing environment variables to the VM using the standard env settings in the container definition: ... spec: ... containers: - name: cirros-vm ... env: - name: MY_FOO_VAR value: foo - name: MY_FOOBAR_VAR value: foobar Virtlet uses Cloud-Init mechanisms to write the values into /etc/cloud/environment file inside the VM which has the same key=value per line format as /etc/environment and can be either read by an application or sourced by a shell: MY_FOO_VAR=foo MY_FOOBAR_VAR=foobar For this environment mechanism to work, the cloud-init implementation inside the VM must be able to handle write_files inside the Cloud-Init user-data.","title":"Defining a VM Pod"},{"location":"reference/vm-pod-spec/#defining-a-vm-pod","text":"The basic idea of a VM pod is that it's a plain Kubernetes pod definition with the following conditions satisfied: It has kubernetes.io/target-runtime: virtlet.cloud annotation so it can be recognized by CRI Proxy . The pod has exactly one container. The container's image has virtlet.cloud/ prefix followed by the image name which is recognized according to Virtlet's image handling rules and used to download the QCOW2 image for the VM. If you have Virtlet running only on some of the nodes in the cluster, you also need to specify either nodeSelector or nodeAffinity for the pod to have it land on a node with Virtlet. If a VM pod lands on a node which doesn't have Virtlet or where Virtlet and CRI Proxy aren't configured properly, you can see the following messages in kubectl describe output for the VM pod (the message can be printed as a single line): Warning Failed 5s (x2 over 17s) kubelet, kubemaster Failed to pull image virtlet.cloud/cirros : rpc error: code = Unknown desc = Error response from daemon: Get https://virtlet.cloud/v2/: dial tcp 50.63.202.10:443: connect: connection refused This means that kubelet is trying to pull the VM image from a Docker registry. It's also possible to construct higher-level Kubernetes objects such as Deployment, StatefulSet or DaemonSet out of VM pods, in which case the template section of the object must follow the above rules for VM pods. Below is an example of a Virtlet pod. The comments describe the particular parts of the pod spec. The following sections will give more details on each part of the spec. # Standard k8s pod header apiVersion: v1 kind: Pod metadata: # the name of the pod name: cirros-vm # See 'Annotations recognized by Virtlet' below annotations: # This tells CRI Proxy that this pod belongs to Virtlet runtime kubernetes.io/target-runtime: virtlet.cloud # An optional annotation specifying the count of virtual CPUs. # Defaults to 1 . VirtletVCPUCount: 1 # CirrOS doesn't load nocloud data from SCSI CD-ROM for some reason VirtletDiskDriver: virtio # inject ssh keys via cloud-init VirtletSSHKeys: | ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCaJEcFDXEK2ZbX0ZLS1EIYFZRbDAcRfuVjpstSc0De8+sV1aiu+dePxdkuDRwqFtCyk6dEZkssjOkBXtri00MECLkir6FcH3kKOJtbJ6vy3uaJc9w1ERo+wyl6SkAh/+JTJkp7QRXj8oylW5E20LsbnA/dIwWzAF51PPwF7A7FtNg9DnwPqMkxFo1Th/buOMKbP5ZA1mmNNtmzbMpMfJATvVyiv3ccsSJKOiyQr6UG+j7sc/7jMVz5Xk34Vd0l8GwcB0334MchHckmqDB142h/NCWTr8oLakDNvkfC1YneAfAO41hDkUbxPtVBG5M/o7P4fxoqiHEX+ZLfRxDtHB53 me@localhost # set root volume size VirtletRootVolumeSize: 1Gi spec: # This nodeAffinity specification tells Kubernetes to run this # pod only on the nodes that have extraRuntime=virtlet label. # This label is used by Virtlet DaemonSet to select nodes # that must have Virtlet runtime affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: extraRuntime operator: In values: - virtlet containers: - name: cirros-vm # This specifies the image to use. # virtlet.cloud/ prefix is used by CRI proxy, the remaining part # of the image name is prepended with https:// and used to download the image image: virtlet.cloud/cirros imagePullPolicy: IfNotPresent # tty and stdin required for `kubectl attach -t` to work tty: true stdin: true resources: limits: # This memory limit is applied to the libvirt domain definition memory: 160Mi","title":"Defining a VM Pod"},{"location":"reference/vm-pod-spec/#annotations-recognized-by-virtlet","text":"The annotations can be specified under annotations key of the metadata part of the pod spec. Note that the values are always strings, but they can be parsed in different way by Virtlet (see Type column). For boolean keys, the string \"true\" (lowercase) is interpreted as a true value. All other values are interpreted as false. Several keys belong to the Cloud-Init settings which are described in detail in the corresponding section . Key Description Value Default kubernetes.io/target-runtime CRI runtime setting for CRI Proxy virtlet.cloud virtlet.cloud VirtletChown9pfsMounts Recursively chown 9pfs mounts boolean \"\" VirtletCloudInitImageType Cloud-Init image type to use \"nocloud\" \"configdrive\" \"\" VirtletCloudInitMetaData The contents of Cloud-Init metadata json / yaml \"\" VirtletCloudInitUserData The contents of Cloud-Init user-data (mergeable) json / yaml \"\" VirtletCloudInitUserDataOverwrite Disable merging of Cloud-Init user-data keys boolean \"\" VirtletCloudInitUserDataScript The contents of Cloud-Init user-data as a script text \"\" VirtletCloudInitUserDataSource Data source for Cloud-Init user-data \"configmap/...\" \"secret/...\" \"\" VirtletCloudInitUserDataSourceEncoding Encoding to use for loading Cloud-Init user-data from a ConfigMap key \"plain\" \"base|4\" VirtletCloudInitUserDataSourceKey ConfigMap key to load Cloud-Init user-data from \"\" VirtletCPUModel CPU model to use \"\" \"host-model\" \"\" VirtletDiskDriver Disk driver to use \"scsi\" \"virtio\" \"scsi\" VirtletFilesFromDataSource Inject files from a ConfigMap or a Secret into the image \"configmap/...\" \"secret/...\" \"\" VirtletLibvirtCPUSetting libvirt CPU model setting yaml \"\" VirtletRootVolumeSize Root volume size quantity \"\" VirtletSSHKeys SSH keys to add to the VM injected via Cloud-Init a list of strings \"\" VirtletSSHKeySource Data source for ssh keys injected via Cloud-Init \"configmap/...\" \"secret/...\" \"\" VirtletVCPUCount The number of vCPUs to assign to the VM pod integer \"1\"","title":"Annotations recognized by Virtlet"},{"location":"reference/vm-pod-spec/#cri-proxy-annotation","text":"Besides Virtlet annotations, there's kubernetes.io/target-runtime: virtlet.cloud annotation which is handled by CRI Proxy . It's important to specify it as well as virtlet.cloud prefix for CRI Proxy to be able to direct requests to Virtlet.","title":"CRI Proxy annotation"},{"location":"reference/vm-pod-spec/#chowning-9pfs-mounts","text":"Setting VirtletChown9pfsMounts to true causes 9pfs mounts to chown their volume contents to make it readable and writable by the VM.","title":"Chowning 9pfs mounts"},{"location":"reference/vm-pod-spec/#cpu-model","text":"VirtletCPUModel: host-model annotation enables nested virtualization. VirtletLibvirtCPUSetting is an expert-only annotation that sets the CPU options for libvirt. The YAML keys correspond to the XML elements and attributes in the libvirt XML definition , but are capitalized. The value of Model field goes into the Value key. For example: Match: exact Model: Fallback: allow Value: core2duo","title":"CPU Model"},{"location":"reference/vm-pod-spec/#disk-driver","text":"The driver is set using VirtletDiskDriver annotation which may have the value of scsi (the default) or virtio . Some OS images may have problem with the default scsi driver, for example, CirrOS can't handle Cloud-Init data unless virtio driver is used.","title":"Disk driver"},{"location":"reference/vm-pod-spec/#injecting-files-into-the-image","text":"By using VirtletFilesFromDataSource annotation, it's possible to place the contents of a ConfigMap or a Secret on the image before booting the VM. For more information, refer to Injecting files into the VM .","title":"Injecting files into the image"},{"location":"reference/vm-pod-spec/#vcpu-count","text":"Virtlet defaults to using just one vCPU per VM. You can change this value by setting VirtletVCPUCount annotation to the desired value, for example, VirtletVCPUCount: \"2\" .","title":"vCPU count"},{"location":"reference/vm-pod-spec/#volume-handling","text":"Virtlet can recognize and handle pod's volumes and container's volumeMounts sections. This can also be used to make the VM use a persistent root filesystem which will survive pod removal and re-creation. For more information on working with volumes, please refer to the Volumes section.","title":"Volume handling"},{"location":"reference/vm-pod-spec/#environment-variables","text":"Virtlet supports passing environment variables to the VM using the standard env settings in the container definition: ... spec: ... containers: - name: cirros-vm ... env: - name: MY_FOO_VAR value: foo - name: MY_FOOBAR_VAR value: foobar Virtlet uses Cloud-Init mechanisms to write the values into /etc/cloud/environment file inside the VM which has the same key=value per line format as /etc/environment and can be either read by an application or sourced by a shell: MY_FOO_VAR=foo MY_FOOBAR_VAR=foobar For this environment mechanism to work, the cloud-init implementation inside the VM must be able to handle write_files inside the Cloud-Init user-data.","title":"Environment variables"},{"location":"reference/vm-pod/","text":"Differences between \"plain\" Kubernetes pods and VM pods Virtlet tries hard to make VM pods appear as plain Kubernetes pods. Still, there are some important differences, including: VM pods can have just one \"container\" You can't use container images for VM pods Some container-specific settings such as network/PID/IPC namespaces, SELinux/AppArmor settings, privileged flag etc. aren't applicable to VM pods Some volume types are handled differently. There are VM-pod-specific settings such as Cloud-Init, persistent rootfs, etc. For more information, see Volumes . kubectl exec and exec readiness/liveness probes aren't supported for VM pods yet There are VM-pod-specific settings such as Cloud-Init , persistent rootfs, etc. Another important point is that when using a persistent root filesystem, the lifetime of the VM is not limited to that of the pod. Despite these differences, there are quite a few Kubernetes features that work for VM pods just as well as for \"plain\" pods, for example, most kubectl commands, pointing services at VM pods, and so on. Besides kubectl , a Virtlet-specific tool called virtletctl can be used to perform Virtlet-specific actions on VM pods and Virtlet processes in the cluster, such as connecting to the VM using SSH and providing VNC connection and dumping cluster diagnostic info. Supported kubectl commands Most kubectl commands' behavior doesn't differ between \"plain\" and VM pods. Exceptions are kubectl exec which isn't supported at the moment, and kubectl attach / kubectl logs which work only if the VM has serial console configured. kubectl attach attaches to the VM serial console. Detaching from the console is done via Ctrl-] . kubectl logs displays the logs for the pod. In case of VM pod, the log is the serial console output. kubectl logs -f , which follows the log as it grows, is supported, too. Using higher-level Kubernetes objects One of the advantages of pod-based approach to running VMs on Kubernetes is an ability to use higher-level Kubernetes objects such as StatefulSets, Deployments, DaemonSets etc. trivially with VMs. Virtlet includes a nested Kubernetes example which makes a nested Kubernetes cluster using a StatefulSet of 3 VM pods, which are initialized using kubeadm . In the k8s-in-k8s example, first we create a headless service that will point domain names k8s-0 , k8s-1 and k8s-2 as resolved by cluster's DNS to the corresponding StatefulSet replicas: apiVersion: v1 kind: Service metadata: name: k8s labels: app: k8s spec: ports: - port: 22 name: ssh clusterIP: None selector: app: inner-k8s Then, we begin defining a StatefulSet with 3 replicas: apiVersion: apps/v1 kind: StatefulSet metadata: name: k8s spec: serviceName: k8s replicas: 3 selector: matchLabels: app: inner-k8s The pods that comprise the StatefulSet are VM pods and thus must have kubernetes.io/target-runtime: virtlet.cloud annotation. Also, we set the root volume size to 4Gi to have some place for Docker images: template: metadata: labels: app: inner-k8s annotations: kubernetes.io/target-runtime: virtlet.cloud # set root volume size VirtletRootVolumeSize: 4Gi Then we add another annotation that will contain Cloud-Init user-data, in which we write some files to adjust Docker settings and add the Kubernetes repository for apt, as well as a provisioning script that will install the necessary packages and then run kubeadm init on k8s-0 and kubeadm join on k8s-1 and k8s-2 . The script makes use of StatefulSet's stable network IDs , so the nodes have names k8s-0 , k8s-1 and k8s-2 that can be resolved by cluster DNS. VirtletCloudInitUserData: | write_files: - path: /etc/systemd/system/docker.service.d/env.conf permissions: 0644 owner: root content: | [Service] Environment= DOCKER_OPTS=--storage-driver=overlay2 - path: /etc/apt/sources.list.d/kubernetes.list permissions: 0644 owner: root content: | deb http://apt.kubernetes.io/ kubernetes-xenial main - path: /usr/local/bin/provision.sh permissions: 0755 owner: root content: | #!/bin/bash set -u -e set -o pipefail curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - apt-get update apt-get install -y docker.io kubelet kubeadm kubectl kubernetes-cni sed -i 's/--cluster-dns=10\\.96\\.0\\.10/--cluster-dns=10.97.0.10/' \\ /etc/systemd/system/kubelet.service.d/10-kubeadm.conf systemctl daemon-reload if [[ $(hostname) =~ -0$ ]]; then # master node kubeadm init --token adcb82.4eae29627dc4c5a6 \\ --pod-network-cidr=10.200.0.0/16 \\ --service-cidr=10.97.0.0/16 \\ --apiserver-cert-extra-sans=127.0.0.1,localhost export KUBECONFIG=/etc/kubernetes/admin.conf export kubever=$(kubectl version | base64 | tr -d '\\n') kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$kubever while ! kubectl get pods -n kube-system -l k8s-app=kube-dns | grep ' 1/1'; do sleep 1 done mkdir -p /root/.kube chmod 700 /root/.kube cp ${KUBECONFIG} /root/.kube/config echo Master setup complete. 2 else # worker node kubeadm join --token adcb82.4eae29627dc4c5a6 \\ --discovery-token-unsafe-skip-ca-verification k8s-0.k8s:6443 echo Node setup complete. 2 fi We then add an ssh public key (corresponding to examples/vmkey ) for the user root : users: - name: root # VirtletSSHKeys only affects 'ubuntu' user for this image, but we want root access ssh-authorized-keys: - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCaJEcFDXEK2ZbX0ZLS1EIYFZRbDAcRfuVjpstSc0De8+sV1aiu+dePxdkuDRwqFtCyk6dEZkssjOkBXtri00MECLkir6FcH3kKOJtbJ6vy3uaJc9w1ERo+wyl6SkAh/+JTJkp7QRXj8oylW5E20LsbnA/dIwWzAF51PPwF7A7FtNg9DnwPqMkxFo1Th/buOMKbP5ZA1mmNNtmzbMpMfJATvVyiv3ccsSJKOiyQr6UG+j7sc/7jMVz5Xk34Vd0l8GwcB0334MchHckmqDB142h/NCWTr8oLakDNvkfC1YneAfAO41hDkUbxPtVBG5M/o7P4fxoqiHEX+ZLfRxDtHB53 me@localhost and make Cloud-Init run the provisioning script when the VM boots: runcmd: - /usr/local/bin/provision.sh After that, we get to the pod spec, in which we limit the possibilities of running the pod to the nodes with extraRuntime=virtlet label where Virtlet daemon pods are placed and use Ubuntu 16.04 image: spec: nodeSelector: extraRuntime: virtlet containers: - name: ubuntu-vm image: virtlet.cloud/cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img imagePullPolicy: IfNotPresent # tty and stdin required for `kubectl attach -t` to work tty: true stdin: true We then specify a readiness probe which will mark each pod as Ready once its ssh port becomes active: readinessProbe: tcpSocket: port: 22 initialDelaySeconds: 5 We could use a more sophisticated check, e.g. by making sure that apiserver is accessible, but for the purpose of the example we use this trivial scheme to keep things simple. Note that kubeadm join on k8s-1 and k8s-2 will keep retrying till kubeadm init on k8s-0 completes its task. In order to test the example, we start it and wait till k8s-0 , k8s-1 and k8s-2 pods appear: $ kubectl apply -f examples/k8s.yaml $ kubectl get pods -w Then we can view the logs on each of the node to see the progress of Kubernetes setup, e.g. $ kubectl logs -f k8s-0 ... [ 226.115652] cloud-init[1513]: Master setup complete. ... After the setup is complete, we can use virtletctl to ssh into the master VM and check the cluster: $ virtletctl ssh root@k8s-0 -- -i examples/vmkey Welcome to Ubuntu 16.04.5 LTS (GNU/Linux 4.4.0-138-generic x86_64) ... root@k8s-0:~# kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-576cbf47c7-8dnh6 1/1 Running 0 69m kube-system coredns-576cbf47c7-q622f 1/1 Running 0 69m kube-system etcd-k8s-0 1/1 Running 0 69m kube-system kube-apiserver-k8s-0 1/1 Running 0 68m kube-system kube-controller-manager-k8s-0 1/1 Running 0 68m kube-system kube-proxy-4dgfx 1/1 Running 0 69m kube-system kube-proxy-jmw6c 1/1 Running 0 69m kube-system kube-proxy-qwbw7 1/1 Running 0 69m kube-system kube-scheduler-k8s-0 1/1 Running 0 68m kube-system weave-net-88jv4 2/2 Running 1 69m kube-system weave-net-kz698 2/2 Running 0 69m kube-system weave-net-rbnmf 2/2 Running 1 69m root@k8s-0:~# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-0 Ready master 69m v1.12.2 k8s-1 Ready none 69m v1.12.2 k8s-2 Ready none 69m v1.12.2","title":"Working with VM Pods"},{"location":"reference/vm-pod/#differences-between-plain-kubernetes-pods-and-vm-pods","text":"Virtlet tries hard to make VM pods appear as plain Kubernetes pods. Still, there are some important differences, including: VM pods can have just one \"container\" You can't use container images for VM pods Some container-specific settings such as network/PID/IPC namespaces, SELinux/AppArmor settings, privileged flag etc. aren't applicable to VM pods Some volume types are handled differently. There are VM-pod-specific settings such as Cloud-Init, persistent rootfs, etc. For more information, see Volumes . kubectl exec and exec readiness/liveness probes aren't supported for VM pods yet There are VM-pod-specific settings such as Cloud-Init , persistent rootfs, etc. Another important point is that when using a persistent root filesystem, the lifetime of the VM is not limited to that of the pod. Despite these differences, there are quite a few Kubernetes features that work for VM pods just as well as for \"plain\" pods, for example, most kubectl commands, pointing services at VM pods, and so on. Besides kubectl , a Virtlet-specific tool called virtletctl can be used to perform Virtlet-specific actions on VM pods and Virtlet processes in the cluster, such as connecting to the VM using SSH and providing VNC connection and dumping cluster diagnostic info.","title":"Differences between \"plain\" Kubernetes pods and VM pods"},{"location":"reference/vm-pod/#supported-kubectl-commands","text":"Most kubectl commands' behavior doesn't differ between \"plain\" and VM pods. Exceptions are kubectl exec which isn't supported at the moment, and kubectl attach / kubectl logs which work only if the VM has serial console configured. kubectl attach attaches to the VM serial console. Detaching from the console is done via Ctrl-] . kubectl logs displays the logs for the pod. In case of VM pod, the log is the serial console output. kubectl logs -f , which follows the log as it grows, is supported, too.","title":"Supported kubectl commands"},{"location":"reference/vm-pod/#using-higher-level-kubernetes-objects","text":"One of the advantages of pod-based approach to running VMs on Kubernetes is an ability to use higher-level Kubernetes objects such as StatefulSets, Deployments, DaemonSets etc. trivially with VMs. Virtlet includes a nested Kubernetes example which makes a nested Kubernetes cluster using a StatefulSet of 3 VM pods, which are initialized using kubeadm . In the k8s-in-k8s example, first we create a headless service that will point domain names k8s-0 , k8s-1 and k8s-2 as resolved by cluster's DNS to the corresponding StatefulSet replicas: apiVersion: v1 kind: Service metadata: name: k8s labels: app: k8s spec: ports: - port: 22 name: ssh clusterIP: None selector: app: inner-k8s Then, we begin defining a StatefulSet with 3 replicas: apiVersion: apps/v1 kind: StatefulSet metadata: name: k8s spec: serviceName: k8s replicas: 3 selector: matchLabels: app: inner-k8s The pods that comprise the StatefulSet are VM pods and thus must have kubernetes.io/target-runtime: virtlet.cloud annotation. Also, we set the root volume size to 4Gi to have some place for Docker images: template: metadata: labels: app: inner-k8s annotations: kubernetes.io/target-runtime: virtlet.cloud # set root volume size VirtletRootVolumeSize: 4Gi Then we add another annotation that will contain Cloud-Init user-data, in which we write some files to adjust Docker settings and add the Kubernetes repository for apt, as well as a provisioning script that will install the necessary packages and then run kubeadm init on k8s-0 and kubeadm join on k8s-1 and k8s-2 . The script makes use of StatefulSet's stable network IDs , so the nodes have names k8s-0 , k8s-1 and k8s-2 that can be resolved by cluster DNS. VirtletCloudInitUserData: | write_files: - path: /etc/systemd/system/docker.service.d/env.conf permissions: 0644 owner: root content: | [Service] Environment= DOCKER_OPTS=--storage-driver=overlay2 - path: /etc/apt/sources.list.d/kubernetes.list permissions: 0644 owner: root content: | deb http://apt.kubernetes.io/ kubernetes-xenial main - path: /usr/local/bin/provision.sh permissions: 0755 owner: root content: | #!/bin/bash set -u -e set -o pipefail curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - apt-get update apt-get install -y docker.io kubelet kubeadm kubectl kubernetes-cni sed -i 's/--cluster-dns=10\\.96\\.0\\.10/--cluster-dns=10.97.0.10/' \\ /etc/systemd/system/kubelet.service.d/10-kubeadm.conf systemctl daemon-reload if [[ $(hostname) =~ -0$ ]]; then # master node kubeadm init --token adcb82.4eae29627dc4c5a6 \\ --pod-network-cidr=10.200.0.0/16 \\ --service-cidr=10.97.0.0/16 \\ --apiserver-cert-extra-sans=127.0.0.1,localhost export KUBECONFIG=/etc/kubernetes/admin.conf export kubever=$(kubectl version | base64 | tr -d '\\n') kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$kubever while ! kubectl get pods -n kube-system -l k8s-app=kube-dns | grep ' 1/1'; do sleep 1 done mkdir -p /root/.kube chmod 700 /root/.kube cp ${KUBECONFIG} /root/.kube/config echo Master setup complete. 2 else # worker node kubeadm join --token adcb82.4eae29627dc4c5a6 \\ --discovery-token-unsafe-skip-ca-verification k8s-0.k8s:6443 echo Node setup complete. 2 fi We then add an ssh public key (corresponding to examples/vmkey ) for the user root : users: - name: root # VirtletSSHKeys only affects 'ubuntu' user for this image, but we want root access ssh-authorized-keys: - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCaJEcFDXEK2ZbX0ZLS1EIYFZRbDAcRfuVjpstSc0De8+sV1aiu+dePxdkuDRwqFtCyk6dEZkssjOkBXtri00MECLkir6FcH3kKOJtbJ6vy3uaJc9w1ERo+wyl6SkAh/+JTJkp7QRXj8oylW5E20LsbnA/dIwWzAF51PPwF7A7FtNg9DnwPqMkxFo1Th/buOMKbP5ZA1mmNNtmzbMpMfJATvVyiv3ccsSJKOiyQr6UG+j7sc/7jMVz5Xk34Vd0l8GwcB0334MchHckmqDB142h/NCWTr8oLakDNvkfC1YneAfAO41hDkUbxPtVBG5M/o7P4fxoqiHEX+ZLfRxDtHB53 me@localhost and make Cloud-Init run the provisioning script when the VM boots: runcmd: - /usr/local/bin/provision.sh After that, we get to the pod spec, in which we limit the possibilities of running the pod to the nodes with extraRuntime=virtlet label where Virtlet daemon pods are placed and use Ubuntu 16.04 image: spec: nodeSelector: extraRuntime: virtlet containers: - name: ubuntu-vm image: virtlet.cloud/cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img imagePullPolicy: IfNotPresent # tty and stdin required for `kubectl attach -t` to work tty: true stdin: true We then specify a readiness probe which will mark each pod as Ready once its ssh port becomes active: readinessProbe: tcpSocket: port: 22 initialDelaySeconds: 5 We could use a more sophisticated check, e.g. by making sure that apiserver is accessible, but for the purpose of the example we use this trivial scheme to keep things simple. Note that kubeadm join on k8s-1 and k8s-2 will keep retrying till kubeadm init on k8s-0 completes its task. In order to test the example, we start it and wait till k8s-0 , k8s-1 and k8s-2 pods appear: $ kubectl apply -f examples/k8s.yaml $ kubectl get pods -w Then we can view the logs on each of the node to see the progress of Kubernetes setup, e.g. $ kubectl logs -f k8s-0 ... [ 226.115652] cloud-init[1513]: Master setup complete. ... After the setup is complete, we can use virtletctl to ssh into the master VM and check the cluster: $ virtletctl ssh root@k8s-0 -- -i examples/vmkey Welcome to Ubuntu 16.04.5 LTS (GNU/Linux 4.4.0-138-generic x86_64) ... root@k8s-0:~# kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-576cbf47c7-8dnh6 1/1 Running 0 69m kube-system coredns-576cbf47c7-q622f 1/1 Running 0 69m kube-system etcd-k8s-0 1/1 Running 0 69m kube-system kube-apiserver-k8s-0 1/1 Running 0 68m kube-system kube-controller-manager-k8s-0 1/1 Running 0 68m kube-system kube-proxy-4dgfx 1/1 Running 0 69m kube-system kube-proxy-jmw6c 1/1 Running 0 69m kube-system kube-proxy-qwbw7 1/1 Running 0 69m kube-system kube-scheduler-k8s-0 1/1 Running 0 68m kube-system weave-net-88jv4 2/2 Running 1 69m kube-system weave-net-kz698 2/2 Running 0 69m kube-system weave-net-rbnmf 2/2 Running 1 69m root@k8s-0:~# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-0 Ready master 69m v1.12.2 k8s-1 Ready none 69m v1.12.2 k8s-2 Ready none 69m v1.12.2","title":"Using higher-level Kubernetes objects"},{"location":"reference/volumes/","text":"Using volumes Virtlet can recognize and handle pod's volumes and container's volumeMounts / volumeDevices sections. These can be used to mount Kubernetes volumes into the VM, as well as attaching block volumes to the VM and specifying a persistent root filesystem for a VM. Consuming raw block PVs Virtlet supports consuming Raw Block Volumes in the VMs. In order to do this, you need a PVC with volumeMode: Block (let's say its name is testpvc ) bound to a PV (which needs also to be volumeMode: Block ). You can use this mechanism with both local and non-local PVs. You can then add the following to pod's volumes: volumes: - name: testpvc persistentVolumeClaim: claimName: local-block-pvc and corresponding volumeDevices entry to the container: volumeDevices: - devicePath: /dev/testpvc name: testpvc Virtlet will ensure that /dev/testpvc inside the VM is a symlink pointing to the device that corresponds to the block volume (for more details on this, see Cloud-Init description. You can also mount the block device inside the VM using cloud-init: VirtletCloudInitUserData: | mounts: - [ /dev/testpvc , /mnt ] See also block PV examples . Persistent root filesystem Although initially Virtlet was only supporting \"cattle\" VMs that had their lifespan limited to the one of the pod, it's now possible to have VMs with persistent root filesystem that survives pod removal and re-creation, too. If a persistent block volume is specified for a pod and listed in container's volumeDevices with devicePath of / : volumeDevices: - devicePath: / name: testpvc the corresponding PV will be used as a persistent root filesystem for a pod. The persistent root filesystem is reused as long as the image SHA256 hash doesn't change. Upon the change of SHA256 hash of the VM image, the PV will be overwritten again. Internally, Virtlet uses sector 0 of the block device to store persistent root filesystem metadata, and the block device visible inside the VM will use the sectors starting from sector 1. Overall, the following algorithm is used: 1. The block device is checked for the presence of Virtlet header. 2. If there's no Virtlet header, a new header is written to the sector 0 and the device is overwritten with the contents of the image. 3. If the header contains a future persistent root filesystem metadata version number, an error is logged and container creation fails. 4. If the header contains mismatching image SHA256 hash, a new header is written to the sector 0 and the device is overwritten with the contents of the image. Unless this algorithm fails on step 3, the VM is booted using the block PV starting from sector 1 as it's boot device. IMPORTANT NOTE: in case if persistent root filesystem is used, cloud-init based network setup is disabled for the VM. This is done because some cloud-init implementations only apply cloud-init network configuration once, but the IP address given to the VM may change if the persistent root filesystem is reused by another pod. See also block PV examples . Consuming ConfigMaps and Secrets If a Secret or ConfigMap volume is specified for a Virtlet pod, its contents is written to the filesystem of the VM using write_files Cloud-Init feature which needs to be supported by the VM's Cloud-Init implementation. 9pfs mounts Specifying volumeMounts with volumes that don't refer to either Secrets, ConfigMaps, block PVs or Virtlet-specific flexvolumes causes Virtlet to mount them using QEMU's VirtFS (9pfs). Note that this means that the performance may be suboptimal in some cases. File permissions can also constitute a problem here; you can set VirtletChown9pfsMounts pod annotation to true to make Virtlet change the owner user/group on the directory recursively to one enabling read-write access for the VM. Using FlexVolumes Virtlet uses custom FlexVolume driver ( virtlet/flexvolume_driver ) to specify block devices for the VMs. Flexvolume options must include type field with one of the following values: qcow2 - ephemeral volume raw - raw device. This flexvolume type is deprecated in favor of Kubernetes' local PVs consumed in BlockVolume mode . ceph - Ceph RBD. This flexvolume type is deprecated in favor of Kubernetes' RBD PVs consumed in BlockVolume mode . Ephemeral Local Storage All ephemeral volumes created by request as well as VM root volumes are stored in the local libvirt storage pool \" volumes \" which is located at /var/lib/virtlet/volumes . The libvirt volume is named using the following scheme: domain-uuid - vol-name-specified-in-the-flexvolume . The flexvolume has capacity option which specifies the size of the ephemeral volume and default to 1024 MB. See the following example: apiVersion: v1 kind: Pod metadata: name: test-vm-pod annotations: kubernetes.io/target-runtime: virtlet.cloud spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: extraRuntime operator: In values: - virtlet containers: - name: test-vm image: download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img volumes: - name: vol1 flexVolume: driver: virtlet/flexvolume_driver options: type: qcow2 capacity: 1024MB - name: vol2 flexVolume: driver: virtlet/flexvolume_driver options: type: qcow2 According to this definition will be created VM-POD with VM with 2 equal volumes, attached, which can be found in \"volumes\" pool under domain-uuid -vol1 and domain-uuid -vol2 . The root volume, which uses the VM's QCOW2 image as its backing file, is exposed as sda device to the guest OS. On a typical Linux system the additional volume disks are assigned to /dev/sdX ( /dev/vdX in case of virtio-blk ) devices in an alphabetical order, so vol1 will be /dev/sdb ( /dev/vdb ) and vol2 will be /dev/sdc ( /dev/vdc ), but please refer to the caveat #3 at the beginning of this document. When a pod is removed, all the volumes related to it are removed too. This includes the root volume and any additional volumes. Root volume size You can set the size of the root volume of a Virtlet VM by using VirtletRootVolumeSize annotation. The specified size must be greater than the QCOW2 volume size, otherwise it will be ignored. Here's an example: metadata: name: my-vm annotations: kubernetes.io/target-runtime: virtlet.cloud VirtletRootVolumeSize: 4Gi This sets the root volume size to 4 GiB unless QCOW2 image size is larger than 4 GiB, in which case the QCOW2 volume size is used. The annotation uses the standard Kubernetes quantity specification format, for more info, see here . Disk drivers Virtlet volumes can use either virtio-blk or virtio-scsi storage backends for the volumes. virtio-scsi is the default, but it can be overridden using VirtletDiskDriver annotation, which can have one of two values: virtio meaning virtio-blk and scsi meaning virtio-scsi (the default). Below is an example of switching a pod to virtio-blk driver: apiVersion: v1 kind: Pod metadata: name: cirros-vm annotations: kubernetes.io/target-runtime: virtlet.cloud VirtletDiskDriver: virtio The values of the VirtletDiskDriver annotation correspond to values of bus attribute of libvirt disk target specification. The selected mechanism is used for the rootfs, nocloud cloud-init CD-ROM and all the flexvolume types that Virtlet supports. Most of the time setting the driver is not necessary, but some OS images may have problem with the default scsi driver, for example, CirrOS can't handle Cloud-Init data unless virtio driver is used. Caveats and limitations The total allowed number of volumes that can be attached to a single VM (including implicit volumes for the boot disk and nocloud cloud-init CD-ROM) is 20 in case of virtio-blk and 26 in case of virtio-scsi driver. The limits can be extended in future. When generating libvirt domain definition, Virtlet constructs disk names as sd + disk-char in case of virtio-scsi and as vd + disk-char in case of virtio-blk , where disk-char is a lowercase latin letter starting with 'a'. The first block device, sda or vda , is used for the boot disk. domain type='qemu' id='2' xmlns:qemu='http://libvirt.org/schemas/domain/qemu/1.0' name de0ae972-4154-4f8f-70ff-48335987b5ce-cirros-vm-rbd /name .... devices emulator /vmwrapper /emulator disk type='file' device='disk' ... target dev='sda' bus='scsi/' ... /disk disk type='file' device='disk' ... target dev='sdb' bus='scsi'/ ... /disk disk type='network' device='disk' ... target dev='sdc' bus='scsi'/ ... /disk ... /devices ... /domain The attached disks are visible by the OS inside VM as hard disk devices /dev/sdb , /dev/sdc and so on ( /dev/vdb , /dev/vdc and so on in case of virtio-blk ). Note that the naming of the devices inside guest OS is usually unpredictable. The use of Virtlet-generated Cloud-Init data is recommended for mounting of the volumes. Virtlet uses udev-provided /dev/disk/by-path/... or, failing that, sysfs information for finding the device inside the virtual machine. Note that both mechanisms are Linux-specific.","title":"Volumes"},{"location":"reference/volumes/#using-volumes","text":"Virtlet can recognize and handle pod's volumes and container's volumeMounts / volumeDevices sections. These can be used to mount Kubernetes volumes into the VM, as well as attaching block volumes to the VM and specifying a persistent root filesystem for a VM.","title":"Using volumes"},{"location":"reference/volumes/#consuming-raw-block-pvs","text":"Virtlet supports consuming Raw Block Volumes in the VMs. In order to do this, you need a PVC with volumeMode: Block (let's say its name is testpvc ) bound to a PV (which needs also to be volumeMode: Block ). You can use this mechanism with both local and non-local PVs. You can then add the following to pod's volumes: volumes: - name: testpvc persistentVolumeClaim: claimName: local-block-pvc and corresponding volumeDevices entry to the container: volumeDevices: - devicePath: /dev/testpvc name: testpvc Virtlet will ensure that /dev/testpvc inside the VM is a symlink pointing to the device that corresponds to the block volume (for more details on this, see Cloud-Init description. You can also mount the block device inside the VM using cloud-init: VirtletCloudInitUserData: | mounts: - [ /dev/testpvc , /mnt ] See also block PV examples .","title":"Consuming raw block PVs"},{"location":"reference/volumes/#persistent-root-filesystem","text":"Although initially Virtlet was only supporting \"cattle\" VMs that had their lifespan limited to the one of the pod, it's now possible to have VMs with persistent root filesystem that survives pod removal and re-creation, too. If a persistent block volume is specified for a pod and listed in container's volumeDevices with devicePath of / : volumeDevices: - devicePath: / name: testpvc the corresponding PV will be used as a persistent root filesystem for a pod. The persistent root filesystem is reused as long as the image SHA256 hash doesn't change. Upon the change of SHA256 hash of the VM image, the PV will be overwritten again. Internally, Virtlet uses sector 0 of the block device to store persistent root filesystem metadata, and the block device visible inside the VM will use the sectors starting from sector 1. Overall, the following algorithm is used: 1. The block device is checked for the presence of Virtlet header. 2. If there's no Virtlet header, a new header is written to the sector 0 and the device is overwritten with the contents of the image. 3. If the header contains a future persistent root filesystem metadata version number, an error is logged and container creation fails. 4. If the header contains mismatching image SHA256 hash, a new header is written to the sector 0 and the device is overwritten with the contents of the image. Unless this algorithm fails on step 3, the VM is booted using the block PV starting from sector 1 as it's boot device. IMPORTANT NOTE: in case if persistent root filesystem is used, cloud-init based network setup is disabled for the VM. This is done because some cloud-init implementations only apply cloud-init network configuration once, but the IP address given to the VM may change if the persistent root filesystem is reused by another pod. See also block PV examples .","title":"Persistent root filesystem"},{"location":"reference/volumes/#consuming-configmaps-and-secrets","text":"If a Secret or ConfigMap volume is specified for a Virtlet pod, its contents is written to the filesystem of the VM using write_files Cloud-Init feature which needs to be supported by the VM's Cloud-Init implementation.","title":"Consuming ConfigMaps and Secrets"},{"location":"reference/volumes/#9pfs-mounts","text":"Specifying volumeMounts with volumes that don't refer to either Secrets, ConfigMaps, block PVs or Virtlet-specific flexvolumes causes Virtlet to mount them using QEMU's VirtFS (9pfs). Note that this means that the performance may be suboptimal in some cases. File permissions can also constitute a problem here; you can set VirtletChown9pfsMounts pod annotation to true to make Virtlet change the owner user/group on the directory recursively to one enabling read-write access for the VM.","title":"9pfs mounts"},{"location":"reference/volumes/#using-flexvolumes","text":"Virtlet uses custom FlexVolume driver ( virtlet/flexvolume_driver ) to specify block devices for the VMs. Flexvolume options must include type field with one of the following values: qcow2 - ephemeral volume raw - raw device. This flexvolume type is deprecated in favor of Kubernetes' local PVs consumed in BlockVolume mode . ceph - Ceph RBD. This flexvolume type is deprecated in favor of Kubernetes' RBD PVs consumed in BlockVolume mode .","title":"Using FlexVolumes"},{"location":"reference/volumes/#ephemeral-local-storage","text":"All ephemeral volumes created by request as well as VM root volumes are stored in the local libvirt storage pool \" volumes \" which is located at /var/lib/virtlet/volumes . The libvirt volume is named using the following scheme: domain-uuid - vol-name-specified-in-the-flexvolume . The flexvolume has capacity option which specifies the size of the ephemeral volume and default to 1024 MB. See the following example: apiVersion: v1 kind: Pod metadata: name: test-vm-pod annotations: kubernetes.io/target-runtime: virtlet.cloud spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: extraRuntime operator: In values: - virtlet containers: - name: test-vm image: download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img volumes: - name: vol1 flexVolume: driver: virtlet/flexvolume_driver options: type: qcow2 capacity: 1024MB - name: vol2 flexVolume: driver: virtlet/flexvolume_driver options: type: qcow2 According to this definition will be created VM-POD with VM with 2 equal volumes, attached, which can be found in \"volumes\" pool under domain-uuid -vol1 and domain-uuid -vol2 . The root volume, which uses the VM's QCOW2 image as its backing file, is exposed as sda device to the guest OS. On a typical Linux system the additional volume disks are assigned to /dev/sdX ( /dev/vdX in case of virtio-blk ) devices in an alphabetical order, so vol1 will be /dev/sdb ( /dev/vdb ) and vol2 will be /dev/sdc ( /dev/vdc ), but please refer to the caveat #3 at the beginning of this document. When a pod is removed, all the volumes related to it are removed too. This includes the root volume and any additional volumes.","title":"Ephemeral Local Storage"},{"location":"reference/volumes/#root-volume-size","text":"You can set the size of the root volume of a Virtlet VM by using VirtletRootVolumeSize annotation. The specified size must be greater than the QCOW2 volume size, otherwise it will be ignored. Here's an example: metadata: name: my-vm annotations: kubernetes.io/target-runtime: virtlet.cloud VirtletRootVolumeSize: 4Gi This sets the root volume size to 4 GiB unless QCOW2 image size is larger than 4 GiB, in which case the QCOW2 volume size is used. The annotation uses the standard Kubernetes quantity specification format, for more info, see here .","title":"Root volume size"},{"location":"reference/volumes/#disk-drivers","text":"Virtlet volumes can use either virtio-blk or virtio-scsi storage backends for the volumes. virtio-scsi is the default, but it can be overridden using VirtletDiskDriver annotation, which can have one of two values: virtio meaning virtio-blk and scsi meaning virtio-scsi (the default). Below is an example of switching a pod to virtio-blk driver: apiVersion: v1 kind: Pod metadata: name: cirros-vm annotations: kubernetes.io/target-runtime: virtlet.cloud VirtletDiskDriver: virtio The values of the VirtletDiskDriver annotation correspond to values of bus attribute of libvirt disk target specification. The selected mechanism is used for the rootfs, nocloud cloud-init CD-ROM and all the flexvolume types that Virtlet supports. Most of the time setting the driver is not necessary, but some OS images may have problem with the default scsi driver, for example, CirrOS can't handle Cloud-Init data unless virtio driver is used.","title":"Disk drivers"},{"location":"reference/volumes/#caveats-and-limitations","text":"The total allowed number of volumes that can be attached to a single VM (including implicit volumes for the boot disk and nocloud cloud-init CD-ROM) is 20 in case of virtio-blk and 26 in case of virtio-scsi driver. The limits can be extended in future. When generating libvirt domain definition, Virtlet constructs disk names as sd + disk-char in case of virtio-scsi and as vd + disk-char in case of virtio-blk , where disk-char is a lowercase latin letter starting with 'a'. The first block device, sda or vda , is used for the boot disk. domain type='qemu' id='2' xmlns:qemu='http://libvirt.org/schemas/domain/qemu/1.0' name de0ae972-4154-4f8f-70ff-48335987b5ce-cirros-vm-rbd /name .... devices emulator /vmwrapper /emulator disk type='file' device='disk' ... target dev='sda' bus='scsi/' ... /disk disk type='file' device='disk' ... target dev='sdb' bus='scsi'/ ... /disk disk type='network' device='disk' ... target dev='sdc' bus='scsi'/ ... /disk ... /devices ... /domain The attached disks are visible by the OS inside VM as hard disk devices /dev/sdb , /dev/sdc and so on ( /dev/vdb , /dev/vdc and so on in case of virtio-blk ). Note that the naming of the devices inside guest OS is usually unpredictable. The use of Virtlet-generated Cloud-Init data is recommended for mounting of the volumes. Virtlet uses udev-provided /dev/disk/by-path/... or, failing that, sysfs information for finding the device inside the virtual machine. Note that both mechanisms are Linux-specific.","title":"Caveats and limitations"},{"location":"reference/virtletctl/virtletctl/","text":"virtletctl Virtlet control tool Synopsis virtletctl provides a number of utilities for Virtet-enabled Kubernetes cluster. Options --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use -h, --help help for virtletctl --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl diag - Virtlet diagnostics virtletctl gen - Generate Kubernetes YAML for Virtlet deployment virtletctl gendoc - Generate Markdown documentation for the commands virtletctl install - Install virtletctl as a kubectl plugin virtletctl ssh - Connect to a VM pod using ssh virtletctl version - Display Virtlet version information virtletctl virsh - Execute a virsh command virtletctl vnc - Provide access to the VNC console of a VM pod","title":"Command Line Tool"},{"location":"reference/virtletctl/virtletctl/#virtletctl","text":"Virtlet control tool","title":"virtletctl"},{"location":"reference/virtletctl/virtletctl/#synopsis","text":"virtletctl provides a number of utilities for Virtet-enabled Kubernetes cluster.","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl/#options","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use -h, --help help for virtletctl --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options"},{"location":"reference/virtletctl/virtletctl/#see-also","text":"virtletctl diag - Virtlet diagnostics virtletctl gen - Generate Kubernetes YAML for Virtlet deployment virtletctl gendoc - Generate Markdown documentation for the commands virtletctl install - Install virtletctl as a kubectl plugin virtletctl ssh - Connect to a VM pod using ssh virtletctl version - Display Virtlet version information virtletctl virsh - Execute a virsh command virtletctl vnc - Provide access to the VNC console of a VM pod","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_diag/","text":"virtletctl diag Virtlet diagnostics Synopsis Retrieve and unpack Virtlet diagnostics information Options -h, --help help for diag Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl - Virtlet control tool virtletctl diag dump - Dump Virtlet diagnostics information virtletctl diag sonobuoy - Add Virtlet sonobuoy plugin to the sonobuoy output virtletctl diag unpack - Unpack Virtlet diagnostics information","title":"Virtletctl diag"},{"location":"reference/virtletctl/virtletctl_diag/#virtletctl-diag","text":"Virtlet diagnostics","title":"virtletctl diag"},{"location":"reference/virtletctl/virtletctl_diag/#synopsis","text":"Retrieve and unpack Virtlet diagnostics information","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_diag/#options","text":"-h, --help help for diag","title":"Options"},{"location":"reference/virtletctl/virtletctl_diag/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_diag/#see-also","text":"virtletctl - Virtlet control tool virtletctl diag dump - Dump Virtlet diagnostics information virtletctl diag sonobuoy - Add Virtlet sonobuoy plugin to the sonobuoy output virtletctl diag unpack - Unpack Virtlet diagnostics information","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_diag_dump/","text":"virtletctl diag dump Dump Virtlet diagnostics information Synopsis Pull Virtlet diagnostics information from the nodes and dump it as a directory tree or JSON virtletctl diag dump output_dir [flags] Options -h, --help help for dump --json Use JSON output Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl diag - Virtlet diagnostics","title":"Virtletctl diag dump"},{"location":"reference/virtletctl/virtletctl_diag_dump/#virtletctl-diag-dump","text":"Dump Virtlet diagnostics information","title":"virtletctl diag dump"},{"location":"reference/virtletctl/virtletctl_diag_dump/#synopsis","text":"Pull Virtlet diagnostics information from the nodes and dump it as a directory tree or JSON virtletctl diag dump output_dir [flags]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_diag_dump/#options","text":"-h, --help help for dump --json Use JSON output","title":"Options"},{"location":"reference/virtletctl/virtletctl_diag_dump/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_diag_dump/#see-also","text":"virtletctl diag - Virtlet diagnostics","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_diag_sonobuoy/","text":"virtletctl diag sonobuoy Add Virtlet sonobuoy plugin to the sonobuoy output Synopsis Find and patch sonobuoy configmap in the yaml that's read from stdin to include Virtlet sonobuoy plugin virtletctl diag sonobuoy [flags] Options -h, --help help for sonobuoy --tag string Set virtlet image tag for the plugin Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl diag - Virtlet diagnostics","title":"Virtletctl diag sonobuoy"},{"location":"reference/virtletctl/virtletctl_diag_sonobuoy/#virtletctl-diag-sonobuoy","text":"Add Virtlet sonobuoy plugin to the sonobuoy output","title":"virtletctl diag sonobuoy"},{"location":"reference/virtletctl/virtletctl_diag_sonobuoy/#synopsis","text":"Find and patch sonobuoy configmap in the yaml that's read from stdin to include Virtlet sonobuoy plugin virtletctl diag sonobuoy [flags]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_diag_sonobuoy/#options","text":"-h, --help help for sonobuoy --tag string Set virtlet image tag for the plugin","title":"Options"},{"location":"reference/virtletctl/virtletctl_diag_sonobuoy/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_diag_sonobuoy/#see-also","text":"virtletctl diag - Virtlet diagnostics","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_diag_unpack/","text":"virtletctl diag unpack Unpack Virtlet diagnostics information Synopsis Read Virtlet diagnostics information as JSON from stdin and unpacks into a directory tree virtletctl diag unpack output_dir [flags] Options -h, --help help for unpack Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl diag - Virtlet diagnostics","title":"Virtletctl diag unpack"},{"location":"reference/virtletctl/virtletctl_diag_unpack/#virtletctl-diag-unpack","text":"Unpack Virtlet diagnostics information","title":"virtletctl diag unpack"},{"location":"reference/virtletctl/virtletctl_diag_unpack/#synopsis","text":"Read Virtlet diagnostics information as JSON from stdin and unpacks into a directory tree virtletctl diag unpack output_dir [flags]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_diag_unpack/#options","text":"-h, --help help for unpack","title":"Options"},{"location":"reference/virtletctl/virtletctl_diag_unpack/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_diag_unpack/#see-also","text":"virtletctl diag - Virtlet diagnostics","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_gen/","text":"virtletctl gen Generate Kubernetes YAML for Virtlet deployment Synopsis This command produces YAML suitable for use with kubectl apply -f - virtletctl gen [flags] Options --compat Produce YAML that's compatible with older Kubernetes versions --crd Dump CRD definitions only --dev Development mode for use with kubeadm-dind-cluster -h, --help help for gen --tag string Set virtlet image tag Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl - Virtlet control tool","title":"Virtletctl gen"},{"location":"reference/virtletctl/virtletctl_gen/#virtletctl-gen","text":"Generate Kubernetes YAML for Virtlet deployment","title":"virtletctl gen"},{"location":"reference/virtletctl/virtletctl_gen/#synopsis","text":"This command produces YAML suitable for use with kubectl apply -f - virtletctl gen [flags]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_gen/#options","text":"--compat Produce YAML that's compatible with older Kubernetes versions --crd Dump CRD definitions only --dev Development mode for use with kubeadm-dind-cluster -h, --help help for gen --tag string Set virtlet image tag","title":"Options"},{"location":"reference/virtletctl/virtletctl_gen/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_gen/#see-also","text":"virtletctl - Virtlet control tool","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_gendoc/","text":"virtletctl gendoc Generate Markdown documentation for the commands Synopsis This command produces documentation for the whole command tree, or the Virtlet configuration data. virtletctl gendoc output_dir [flags] Options --config Produce documentation for Virtlet config -h, --help help for gendoc Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl - Virtlet control tool","title":"Virtletctl gendoc"},{"location":"reference/virtletctl/virtletctl_gendoc/#virtletctl-gendoc","text":"Generate Markdown documentation for the commands","title":"virtletctl gendoc"},{"location":"reference/virtletctl/virtletctl_gendoc/#synopsis","text":"This command produces documentation for the whole command tree, or the Virtlet configuration data. virtletctl gendoc output_dir [flags]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_gendoc/#options","text":"--config Produce documentation for Virtlet config -h, --help help for gendoc","title":"Options"},{"location":"reference/virtletctl/virtletctl_gendoc/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_gendoc/#see-also","text":"virtletctl - Virtlet control tool","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_install/","text":"virtletctl install Install virtletctl as a kubectl plugin Synopsis This command install virtletctl as a kubectl plugin. After running this command, it becomes possible to run virtletctl via 'kubectl plugin virt'. virtletctl install [flags] Options -h, --help help for install Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl - Virtlet control tool","title":"Virtletctl install"},{"location":"reference/virtletctl/virtletctl_install/#virtletctl-install","text":"Install virtletctl as a kubectl plugin","title":"virtletctl install"},{"location":"reference/virtletctl/virtletctl_install/#synopsis","text":"This command install virtletctl as a kubectl plugin. After running this command, it becomes possible to run virtletctl via 'kubectl plugin virt'. virtletctl install [flags]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_install/#options","text":"-h, --help help for install","title":"Options"},{"location":"reference/virtletctl/virtletctl_install/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_install/#see-also","text":"virtletctl - Virtlet control tool","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_ssh/","text":"virtletctl ssh Connect to a VM pod using ssh Synopsis This command runs ssh and makes it connect to a VM pod. virtletctl ssh [flags] user@pod -- [ssh args...] Options -h, --help help for ssh Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl - Virtlet control tool","title":"Virtletctl ssh"},{"location":"reference/virtletctl/virtletctl_ssh/#virtletctl-ssh","text":"Connect to a VM pod using ssh","title":"virtletctl ssh"},{"location":"reference/virtletctl/virtletctl_ssh/#synopsis","text":"This command runs ssh and makes it connect to a VM pod. virtletctl ssh [flags] user@pod -- [ssh args...]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_ssh/#options","text":"-h, --help help for ssh","title":"Options"},{"location":"reference/virtletctl/virtletctl_ssh/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_ssh/#see-also","text":"virtletctl - Virtlet control tool","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_version/","text":"virtletctl version Display Virtlet version information Synopsis Display information about virtletctl version and Virtlet versions on the nodes virtletctl version [flags] Options --client Print virtletctl version only -h, --help help for version -o, --output string One of 'text', 'short', 'yaml' or 'json' (default text ) --short Print just the version number(s) (same as -o short) Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl - Virtlet control tool","title":"Virtletctl version"},{"location":"reference/virtletctl/virtletctl_version/#virtletctl-version","text":"Display Virtlet version information","title":"virtletctl version"},{"location":"reference/virtletctl/virtletctl_version/#synopsis","text":"Display information about virtletctl version and Virtlet versions on the nodes virtletctl version [flags]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_version/#options","text":"--client Print virtletctl version only -h, --help help for version -o, --output string One of 'text', 'short', 'yaml' or 'json' (default text ) --short Print just the version number(s) (same as -o short)","title":"Options"},{"location":"reference/virtletctl/virtletctl_version/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_version/#see-also","text":"virtletctl - Virtlet control tool","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_virsh/","text":"virtletctl virsh Execute a virsh command Synopsis This command executes libvirt virsh command. A VM pod name in the form @podname is translated to the corresponding libvirt domain name. If @podname is specified, the target k8s node name is inferred automatically based on the information of the VM pod. In case if no @podname is specified, the command is executed on every node and the output for every node is prepended with a line with the node name and corresponding Virtlet pod name. virtletctl virsh [flags] virsh_command -- [virsh_command_args...] Options -h, --help help for virsh --node string the name of the target node Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl - Virtlet control tool","title":"Virtletctl virsh"},{"location":"reference/virtletctl/virtletctl_virsh/#virtletctl-virsh","text":"Execute a virsh command","title":"virtletctl virsh"},{"location":"reference/virtletctl/virtletctl_virsh/#synopsis","text":"This command executes libvirt virsh command. A VM pod name in the form @podname is translated to the corresponding libvirt domain name. If @podname is specified, the target k8s node name is inferred automatically based on the information of the VM pod. In case if no @podname is specified, the command is executed on every node and the output for every node is prepended with a line with the node name and corresponding Virtlet pod name. virtletctl virsh [flags] virsh_command -- [virsh_command_args...]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_virsh/#options","text":"-h, --help help for virsh --node string the name of the target node","title":"Options"},{"location":"reference/virtletctl/virtletctl_virsh/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_virsh/#see-also","text":"virtletctl - Virtlet control tool","title":"SEE ALSO"},{"location":"reference/virtletctl/virtletctl_vnc/","text":"virtletctl vnc Provide access to the VNC console of a VM pod Synopsis This command forwards a local port to the VNC port used by the specified VM pod. If no local port number is provided, a random available port is picked instead. The port number is displayed after the forwarding is set up, after which the commands enters an endless loop until it's interrupted with Ctrl-C. virtletctl vnc pod [port] [flags] Options -h, --help help for vnc Options inherited from parent commands --alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging SEE ALSO virtletctl - Virtlet control tool","title":"Virtletctl vnc"},{"location":"reference/virtletctl/virtletctl_vnc/#virtletctl-vnc","text":"Provide access to the VNC console of a VM pod","title":"virtletctl vnc"},{"location":"reference/virtletctl/virtletctl_vnc/#synopsis","text":"This command forwards a local port to the VNC port used by the specified VM pod. If no local port number is provided, a random available port is picked instead. The port number is displayed after the forwarding is set up, after which the commands enters an endless loop until it's interrupted with Ctrl-C. virtletctl vnc pod [port] [flags]","title":"Synopsis"},{"location":"reference/virtletctl/virtletctl_vnc/#options","text":"-h, --help help for vnc","title":"Options"},{"location":"reference/virtletctl/virtletctl_vnc/#options-inherited-from-parent-commands","text":"--alsologtostderr log to standard error as well as files --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. --log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) --log-dir string If non-empty, write log files in this directory --logtostderr log to standard error instead of files -n, --namespace string If present, the namespace scope for this CLI request --password string Password for basic authentication to the API server --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default 0 ) -s, --server string The address and port of the Kubernetes API server --stderrthreshold severity logs at or above this threshold go to stderr (default 2) --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --username string Username for basic authentication to the API server -v, --v Level log level for V logs --virtlet-runtime string the name of virtlet runtime used in kubernetes.io/target-runtime annotation (default virtlet.cloud ) --vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging","title":"Options inherited from parent commands"},{"location":"reference/virtletctl/virtletctl_vnc/#see-also","text":"virtletctl - Virtlet control tool","title":"SEE ALSO"},{"location":"user-guide/installing-virtlet/","text":"Virtlet 101 content goes here.","title":"Installing Virtlet"}]}